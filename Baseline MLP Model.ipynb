{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65e5919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import tensorflow as tf\n",
    "\n",
    "f = h5py.File('mouse1sample1.hdf5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2763e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_cells = []\n",
    "annotations = []\n",
    "for cell_id in f['cells']:\n",
    "    cell = f['cells'][cell_id]\n",
    "    ann = dict(cell.attrs)['annotation']\n",
    "    if ann != 'unannotated':\n",
    "        annotated_cells.append(cell_id)\n",
    "        annotations.append(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4afbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_count = Counter(annotations)\n",
    "print(\"Number of Annotated Samples:\", len(annotated_cells))\n",
    "print(\"Num of Cell Types:\", len(annotations_count))\n",
    "print(\"Max Number of Samples per Cell Type:\", max(annotations_count.values()))\n",
    "print(\"Min Number of Samples per Cell Type:\", min(annotations_count.values()))\n",
    "print(\"Average Number of Samples per Cell Type:\", sum(annotations_count.values())/93)\n",
    "\n",
    "#graph of num of samples across cell-types \n",
    "plt.bar(np.arange(0,93), annotations_count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283db583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating gene expression table -- time intensive computation\n",
    "# df = pd.DataFrame()\n",
    "# for cell_id in annotated_cells:\n",
    "#     cell = f['cells'][cell_id]\n",
    "#     gene_counts = []\n",
    "#     for z in cell.attrs['zslices']: # for each z-slice corresponding to cell\n",
    "#         spot_genes = cell['spot_genes'][z] # get spot_genes\n",
    "#         for gene in spot_genes: # iterate over spot_genes \n",
    "#             gene_counts.append(gene.decode())\n",
    "#     gene_counts = dict(Counter(gene_counts)) # get count of all genes for cell\n",
    "#     df = df.append(gene_counts, ignore_index=True) # add row to pd dataframe\n",
    "# df = df.fillna(0)\n",
    "# df.to_csv('geneExpression.csv', sep='\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f2484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating one-hot coded vectors for cell-type (labels for multi)\n",
    "annotation_indices = {k: v for v, k in enumerate(list(annotations_count.keys()))}\n",
    "labels = np.zeros((len(annotated_cells), len(annotation_indices)))\n",
    "for index in range(0, len(annotated_cells)):\n",
    "    cell = f['cells'][annotated_cells[index]]\n",
    "    ann = dict(cell.attrs)['annotation']\n",
    "    arr_index = annotation_indices[ann]\n",
    "    labels[index][arr_index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a628cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = loadtxt('geneExpression.csv', delimiter=',')\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cee81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize + scale gene expression data + remove outliers (code from ACTINN paper)\n",
    "total_set = np.divide(dataset, np.sum(dataset, axis=0, keepdims=True)) * 10000\n",
    "total_set = np.log2(total_set+1)\n",
    "expr = np.sum(total_set, axis=1)\n",
    "total_set = total_set[np.logical_and(expr >= np.percentile(expr, 1), expr <= np.percentile(expr, 99)),]\n",
    "total_labels = labels[np.logical_and(expr >= np.percentile(expr, 1), expr <= np.percentile(expr, 99)),]\n",
    "cv = np.std(total_set, axis=1) / np.mean(total_set, axis=1)\n",
    "total_set = total_set[np.logical_and(cv >= np.percentile(cv, 1), cv <= np.percentile(cv, 99)),]\n",
    "total_labels = total_labels[np.logical_and(cv >= np.percentile(cv, 1), cv <= np.percentile(cv, 99)),]\n",
    "\n",
    "dataset=total_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test, train_y, test_y = train_test_split(dataset, total_labels, test_size=0.3)\n",
    "\n",
    "test, val, test_y, val_y = train_test_split(test, test_y, test_size=0.5)\n",
    "print(train.shape, train_y.shape)\n",
    "print(val.shape, val_y.shape)\n",
    "print(test.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39653b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# followed model parameters + layers according to ACTINN paper \n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Input(252),\n",
    "                                    tf.keras.layers.Dense(100, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(50, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(25, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(93, activation=tf.nn.softmax)])\n",
    "lr= tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.0001,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.95,\n",
    "    staircase=True)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=tf.optimizers.Adam(learning_rate=lr), metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(train, train_y, batch_size=128, epochs=50, validation_data=(val, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test)\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "y_test=np.argmax(test_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d6205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
