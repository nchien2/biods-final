{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "398f9a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e01c0874",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_scores = pd.read_csv('merfish_M1S1_filtered_periph_scores.csv')\n",
    "p_scores = p_scores.loc[p_scores['annotation'] != 'unannotated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e7c9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 192 genes\n",
      "There are 17312 unique cells\n"
     ]
    }
   ],
   "source": [
    "# intensize computation: results stored in periphery_data.npy\n",
    "num_unique_cells = (p_scores['cell_id']).unique().shape[0]\n",
    "num_genes = (p_scores['gene']).unique().shape[0]\n",
    "print(\"There are\", num_genes, \"genes\")\n",
    "print(\"There are\", num_unique_cells, \"unique cells\")\n",
    "\n",
    "annotation_indices = {k: v for v, k in enumerate(list(p_scores['annotation'].unique()))}\n",
    "cell_indices = {k: v for v, k in enumerate(list(p_scores['cell_id'].unique()))}\n",
    "gene_indices = {k: v for v, k in enumerate(list(p_scores['gene'].unique()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e8c747",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1750/3996644501.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_unique_cells\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_genes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcell_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cell_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcell_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ne__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5501\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5502\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5504\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# intensize computation: results stored in periphery_labels.npy\n",
    "# x data shape(num_unique_cells, gene_periphery_scores)\n",
    "data = np.zeros((num_unique_cells, num_genes))\n",
    "for cell in cell_indices:\n",
    "    subset = p_scores.loc[p_scores['cell_id'] == cell]\n",
    "    for index, s in subset.iterrows():\n",
    "        cell_index = cell_indices[cell]\n",
    "        gene_index = gene_indices[s['gene']]\n",
    "        data[cell_index][gene_index] = s['periphery_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd1de5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3265/4272844761.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'periphery_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'periphery_labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "np.save('periphery_data', data)\n",
    "np.save('periphery_labels', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b377e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y data \n",
    "labels = np.zeros((num_unique_cells, len(annotation_indices)))\n",
    "for cell in cell_indices:\n",
    "    ann = list(p_scores.loc[p_scores['cell_id'] == cell]['annotation'])[0]\n",
    "    arr_index = annotation_indices[ann]\n",
    "    labels[cell_indices[cell]][arr_index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79863b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17312, 192)\n",
      "(17312, 80)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('periphery_data.npy')\n",
    "labels = np.load('periphery_labels.npy')\n",
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "defc0997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = np.std(data, axis=0) / np.mean(data, axis=0)\n",
    "# data = data[:,np.logical_and(cv >= np.percentile(cv, 1), cv <= np.percentile(cv, 99))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5602dff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = np.sum(np.square(data), axis=1)\n",
    "d = data[np.logical_and(expr >= np.percentile(expr, 1), expr <= np.percentile(expr, 99)),]\n",
    "l = labels[np.logical_and(expr >= np.percentile(expr, 1), expr <= np.percentile(expr, 99)),]\n",
    "# cv = np.std(total_set, axis=1) / np.mean(total_set, axis=1)\n",
    "# total_set = total_set[np.logical_and(cv >= np.percentile(cv, 1), cv <= np.percentile(cv, 99)),]\n",
    "# total_labels = total_labels[np.logical_and(cv >= np.percentile(cv, 1), cv <= np.percentile(cv, 99)),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d74a581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16971, 192)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3bc1b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16971, 80)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bedc7cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12118, 192) (12118, 80)\n",
      "(2597, 192) (2597, 80)\n",
      "(2597, 192) (2597, 80)\n"
     ]
    }
   ],
   "source": [
    "# split data into train, val and test datasets\n",
    "train, test, train_y, test_y = train_test_split(data, labels, test_size=0.3)\n",
    "\n",
    "test, val, test_y, val_y = train_test_split(test, test_y, test_size=0.5)\n",
    "print(train.shape, train_y.shape)\n",
    "print(val.shape, val_y.shape)\n",
    "print(test.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "660fa4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-05 23:09:00.824660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-05 23:09:00.921859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-05 23:09:00.922699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-05 23:09:00.924545: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-05 23:09:00.925249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-05 23:09:00.926031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-05 23:09:00.926759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-05 23:09:02.932815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-05 23:09:02.933806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-05 23:09:02.934659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-05 23:09:02.936524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10819 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
      "2021-11-05 23:09:03.261739: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               19300     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 80)                2080      \n",
      "=================================================================\n",
      "Total params: 27,705\n",
      "Trainable params: 27,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "95/95 [==============================] - 2s 6ms/step - loss: 4.3638 - accuracy: 0.0458 - val_loss: 4.3433 - val_accuracy: 0.0593\n",
      "Epoch 2/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.2942 - accuracy: 0.0680 - val_loss: 4.2326 - val_accuracy: 0.0682\n",
      "Epoch 3/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.1141 - accuracy: 0.0687 - val_loss: 3.9951 - val_accuracy: 0.0682\n",
      "Epoch 4/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 3.8371 - accuracy: 0.0686 - val_loss: 3.7400 - val_accuracy: 0.0682\n",
      "Epoch 5/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 3.6241 - accuracy: 0.0686 - val_loss: 3.5927 - val_accuracy: 0.0709\n",
      "Epoch 6/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 3.5120 - accuracy: 0.1159 - val_loss: 3.5195 - val_accuracy: 0.1236\n",
      "Epoch 7/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 3.4576 - accuracy: 0.1242 - val_loss: 3.4797 - val_accuracy: 0.1328\n",
      "Epoch 8/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 3.4212 - accuracy: 0.1375 - val_loss: 3.4469 - val_accuracy: 0.1494\n",
      "Epoch 9/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 3.3880 - accuracy: 0.1575 - val_loss: 3.4157 - val_accuracy: 0.1663\n",
      "Epoch 10/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 3.3539 - accuracy: 0.1695 - val_loss: 3.3821 - val_accuracy: 0.1744\n",
      "Epoch 11/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 3.3181 - accuracy: 0.1797 - val_loss: 3.3465 - val_accuracy: 0.1864\n",
      "Epoch 12/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 3.2800 - accuracy: 0.1894 - val_loss: 3.3088 - val_accuracy: 0.1968\n",
      "Epoch 13/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 3.2396 - accuracy: 0.2004 - val_loss: 3.2695 - val_accuracy: 0.2041\n",
      "Epoch 14/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 3.1972 - accuracy: 0.2066 - val_loss: 3.2279 - val_accuracy: 0.2083\n",
      "Epoch 15/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 3.1522 - accuracy: 0.2119 - val_loss: 3.1852 - val_accuracy: 0.2133\n",
      "Epoch 16/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 3.1066 - accuracy: 0.2193 - val_loss: 3.1429 - val_accuracy: 0.2179\n",
      "Epoch 17/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 3.0618 - accuracy: 0.2238 - val_loss: 3.1008 - val_accuracy: 0.2229\n",
      "Epoch 18/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 3.0179 - accuracy: 0.2318 - val_loss: 3.0600 - val_accuracy: 0.2303\n",
      "Epoch 19/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.9759 - accuracy: 0.2415 - val_loss: 3.0222 - val_accuracy: 0.2349\n",
      "Epoch 20/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.9361 - accuracy: 0.2481 - val_loss: 2.9852 - val_accuracy: 0.2422\n",
      "Epoch 21/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.8989 - accuracy: 0.2563 - val_loss: 2.9518 - val_accuracy: 0.2476\n",
      "Epoch 22/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.8643 - accuracy: 0.2616 - val_loss: 2.9218 - val_accuracy: 0.2603\n",
      "Epoch 23/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.8324 - accuracy: 0.2694 - val_loss: 2.8932 - val_accuracy: 0.2630\n",
      "Epoch 24/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.8027 - accuracy: 0.2747 - val_loss: 2.8668 - val_accuracy: 0.2703\n",
      "Epoch 25/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.7749 - accuracy: 0.2798 - val_loss: 2.8424 - val_accuracy: 0.2734\n",
      "Epoch 26/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.7488 - accuracy: 0.2862 - val_loss: 2.8196 - val_accuracy: 0.2776\n",
      "Epoch 27/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.7243 - accuracy: 0.2899 - val_loss: 2.7986 - val_accuracy: 0.2819\n",
      "Epoch 28/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.7008 - accuracy: 0.2938 - val_loss: 2.7789 - val_accuracy: 0.2888\n",
      "Epoch 29/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.6782 - accuracy: 0.2996 - val_loss: 2.7595 - val_accuracy: 0.2873\n",
      "Epoch 30/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.6567 - accuracy: 0.3046 - val_loss: 2.7422 - val_accuracy: 0.2919\n",
      "Epoch 31/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.6360 - accuracy: 0.3076 - val_loss: 2.7239 - val_accuracy: 0.2946\n",
      "Epoch 32/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.6162 - accuracy: 0.3126 - val_loss: 2.7077 - val_accuracy: 0.3000\n",
      "Epoch 33/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.5963 - accuracy: 0.3178 - val_loss: 2.6913 - val_accuracy: 0.3015\n",
      "Epoch 34/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.5768 - accuracy: 0.3224 - val_loss: 2.6752 - val_accuracy: 0.3077\n",
      "Epoch 35/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.5584 - accuracy: 0.3256 - val_loss: 2.6602 - val_accuracy: 0.3069\n",
      "Epoch 36/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.5399 - accuracy: 0.3291 - val_loss: 2.6446 - val_accuracy: 0.3111\n",
      "Epoch 37/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.5214 - accuracy: 0.3311 - val_loss: 2.6301 - val_accuracy: 0.3169\n",
      "Epoch 38/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.5032 - accuracy: 0.3347 - val_loss: 2.6145 - val_accuracy: 0.3192\n",
      "Epoch 39/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.4856 - accuracy: 0.3409 - val_loss: 2.6001 - val_accuracy: 0.3231\n",
      "Epoch 40/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.4675 - accuracy: 0.3438 - val_loss: 2.5855 - val_accuracy: 0.3254\n",
      "Epoch 41/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.4497 - accuracy: 0.3472 - val_loss: 2.5713 - val_accuracy: 0.3300\n",
      "Epoch 42/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.4320 - accuracy: 0.3526 - val_loss: 2.5569 - val_accuracy: 0.3346\n",
      "Epoch 43/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.4143 - accuracy: 0.3586 - val_loss: 2.5428 - val_accuracy: 0.3342\n",
      "Epoch 44/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.3968 - accuracy: 0.3605 - val_loss: 2.5291 - val_accuracy: 0.3377\n",
      "Epoch 45/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.3792 - accuracy: 0.3659 - val_loss: 2.5139 - val_accuracy: 0.3412\n",
      "Epoch 46/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.3620 - accuracy: 0.3682 - val_loss: 2.4998 - val_accuracy: 0.3454\n",
      "Epoch 47/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.3446 - accuracy: 0.3746 - val_loss: 2.4862 - val_accuracy: 0.3504\n",
      "Epoch 48/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.3275 - accuracy: 0.3774 - val_loss: 2.4718 - val_accuracy: 0.3527\n",
      "Epoch 49/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.3103 - accuracy: 0.3824 - val_loss: 2.4581 - val_accuracy: 0.3577\n",
      "Epoch 50/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.2930 - accuracy: 0.3864 - val_loss: 2.4449 - val_accuracy: 0.3593\n",
      "Epoch 51/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.2759 - accuracy: 0.3890 - val_loss: 2.4323 - val_accuracy: 0.3608\n",
      "Epoch 52/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 4ms/step - loss: 2.2589 - accuracy: 0.3943 - val_loss: 2.4176 - val_accuracy: 0.3623\n",
      "Epoch 53/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.2418 - accuracy: 0.3973 - val_loss: 2.4054 - val_accuracy: 0.3647\n",
      "Epoch 54/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.2252 - accuracy: 0.4015 - val_loss: 2.3906 - val_accuracy: 0.3677\n",
      "Epoch 55/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.2086 - accuracy: 0.4033 - val_loss: 2.3774 - val_accuracy: 0.3693\n",
      "Epoch 56/300\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 2.1918 - accuracy: 0.4095 - val_loss: 2.3654 - val_accuracy: 0.3743\n",
      "Epoch 57/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.1759 - accuracy: 0.4114 - val_loss: 2.3520 - val_accuracy: 0.3754\n",
      "Epoch 58/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.1596 - accuracy: 0.4162 - val_loss: 2.3410 - val_accuracy: 0.3781\n",
      "Epoch 59/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.1437 - accuracy: 0.4204 - val_loss: 2.3262 - val_accuracy: 0.3843\n",
      "Epoch 60/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.1278 - accuracy: 0.4280 - val_loss: 2.3131 - val_accuracy: 0.3897\n",
      "Epoch 61/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.1121 - accuracy: 0.4315 - val_loss: 2.3022 - val_accuracy: 0.3928\n",
      "Epoch 62/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.0968 - accuracy: 0.4374 - val_loss: 2.2908 - val_accuracy: 0.3966\n",
      "Epoch 63/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.0817 - accuracy: 0.4433 - val_loss: 2.2798 - val_accuracy: 0.3985\n",
      "Epoch 64/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.0669 - accuracy: 0.4457 - val_loss: 2.2665 - val_accuracy: 0.4097\n",
      "Epoch 65/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.0521 - accuracy: 0.4535 - val_loss: 2.2556 - val_accuracy: 0.4078\n",
      "Epoch 66/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.0379 - accuracy: 0.4568 - val_loss: 2.2454 - val_accuracy: 0.4101\n",
      "Epoch 67/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.0238 - accuracy: 0.4601 - val_loss: 2.2345 - val_accuracy: 0.4139\n",
      "Epoch 68/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 2.0098 - accuracy: 0.4626 - val_loss: 2.2251 - val_accuracy: 0.4162\n",
      "Epoch 69/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.9963 - accuracy: 0.4640 - val_loss: 2.2140 - val_accuracy: 0.4182\n",
      "Epoch 70/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.9831 - accuracy: 0.4680 - val_loss: 2.2048 - val_accuracy: 0.4243\n",
      "Epoch 71/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.9698 - accuracy: 0.4681 - val_loss: 2.1943 - val_accuracy: 0.4270\n",
      "Epoch 72/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.9569 - accuracy: 0.4735 - val_loss: 2.1846 - val_accuracy: 0.4282\n",
      "Epoch 73/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.9444 - accuracy: 0.4763 - val_loss: 2.1767 - val_accuracy: 0.4324\n",
      "Epoch 74/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.9323 - accuracy: 0.4762 - val_loss: 2.1658 - val_accuracy: 0.4317\n",
      "Epoch 75/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.9200 - accuracy: 0.4787 - val_loss: 2.1574 - val_accuracy: 0.4355\n",
      "Epoch 76/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.9079 - accuracy: 0.4828 - val_loss: 2.1503 - val_accuracy: 0.4343\n",
      "Epoch 77/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.8969 - accuracy: 0.4849 - val_loss: 2.1416 - val_accuracy: 0.4351\n",
      "Epoch 78/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.8854 - accuracy: 0.4861 - val_loss: 2.1333 - val_accuracy: 0.4394\n",
      "Epoch 79/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.8742 - accuracy: 0.4882 - val_loss: 2.1244 - val_accuracy: 0.4432\n",
      "Epoch 80/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.8631 - accuracy: 0.4900 - val_loss: 2.1167 - val_accuracy: 0.4451\n",
      "Epoch 81/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.8522 - accuracy: 0.4920 - val_loss: 2.1110 - val_accuracy: 0.4447\n",
      "Epoch 82/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.8420 - accuracy: 0.4948 - val_loss: 2.1036 - val_accuracy: 0.4444\n",
      "Epoch 83/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.8318 - accuracy: 0.4964 - val_loss: 2.0985 - val_accuracy: 0.4482\n",
      "Epoch 84/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.8216 - accuracy: 0.5003 - val_loss: 2.0906 - val_accuracy: 0.4486\n",
      "Epoch 85/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.8117 - accuracy: 0.5028 - val_loss: 2.0835 - val_accuracy: 0.4501\n",
      "Epoch 86/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.8018 - accuracy: 0.5038 - val_loss: 2.0782 - val_accuracy: 0.4536\n",
      "Epoch 87/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.7922 - accuracy: 0.5070 - val_loss: 2.0713 - val_accuracy: 0.4555\n",
      "Epoch 88/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.7831 - accuracy: 0.5077 - val_loss: 2.0650 - val_accuracy: 0.4532\n",
      "Epoch 89/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.7740 - accuracy: 0.5110 - val_loss: 2.0590 - val_accuracy: 0.4582\n",
      "Epoch 90/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.7647 - accuracy: 0.5127 - val_loss: 2.0534 - val_accuracy: 0.4601\n",
      "Epoch 91/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.7557 - accuracy: 0.5149 - val_loss: 2.0477 - val_accuracy: 0.4598\n",
      "Epoch 92/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.7475 - accuracy: 0.5161 - val_loss: 2.0415 - val_accuracy: 0.4625\n",
      "Epoch 93/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.7387 - accuracy: 0.5191 - val_loss: 2.0364 - val_accuracy: 0.4644\n",
      "Epoch 94/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.7299 - accuracy: 0.5196 - val_loss: 2.0326 - val_accuracy: 0.4659\n",
      "Epoch 95/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.7214 - accuracy: 0.5220 - val_loss: 2.0260 - val_accuracy: 0.4659\n",
      "Epoch 96/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.7135 - accuracy: 0.5237 - val_loss: 2.0230 - val_accuracy: 0.4671\n",
      "Epoch 97/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.7057 - accuracy: 0.5243 - val_loss: 2.0179 - val_accuracy: 0.4686\n",
      "Epoch 98/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.6968 - accuracy: 0.5275 - val_loss: 2.0147 - val_accuracy: 0.4702\n",
      "Epoch 99/300\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 1.6892 - accuracy: 0.5299 - val_loss: 2.0070 - val_accuracy: 0.4725\n",
      "Epoch 100/300\n",
      "95/95 [==============================] - 1s 9ms/step - loss: 1.6812 - accuracy: 0.5308 - val_loss: 2.0037 - val_accuracy: 0.4732\n",
      "Epoch 101/300\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 1.6736 - accuracy: 0.5325 - val_loss: 2.0010 - val_accuracy: 0.4736\n",
      "Epoch 102/300\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 1.6660 - accuracy: 0.5331 - val_loss: 1.9947 - val_accuracy: 0.4767\n",
      "Epoch 103/300\n",
      "95/95 [==============================] - ETA: 0s - loss: 1.6598 - accuracy: 0.53 - 1s 8ms/step - loss: 1.6581 - accuracy: 0.5366 - val_loss: 1.9909 - val_accuracy: 0.4759\n",
      "Epoch 104/300\n",
      "95/95 [==============================] - 1s 9ms/step - loss: 1.6509 - accuracy: 0.5381 - val_loss: 1.9890 - val_accuracy: 0.4752\n",
      "Epoch 105/300\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 1.6435 - accuracy: 0.5392 - val_loss: 1.9822 - val_accuracy: 0.4771\n",
      "Epoch 106/300\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 1.6367 - accuracy: 0.5405 - val_loss: 1.9805 - val_accuracy: 0.4759\n",
      "Epoch 107/300\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 1.6293 - accuracy: 0.5437 - val_loss: 1.9741 - val_accuracy: 0.4806\n",
      "Epoch 108/300\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 1.6224 - accuracy: 0.5434 - val_loss: 1.9724 - val_accuracy: 0.4782\n",
      "Epoch 109/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 1s 6ms/step - loss: 1.6154 - accuracy: 0.5470 - val_loss: 1.9674 - val_accuracy: 0.4790\n",
      "Epoch 110/300\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 1.6085 - accuracy: 0.5477 - val_loss: 1.9644 - val_accuracy: 0.4829\n",
      "Epoch 111/300\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 1.6015 - accuracy: 0.5501 - val_loss: 1.9614 - val_accuracy: 0.4829\n",
      "Epoch 112/300\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 1.5947 - accuracy: 0.5501 - val_loss: 1.9573 - val_accuracy: 0.4813\n",
      "Epoch 113/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.5881 - accuracy: 0.5531 - val_loss: 1.9550 - val_accuracy: 0.4844\n",
      "Epoch 114/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.5817 - accuracy: 0.5557 - val_loss: 1.9506 - val_accuracy: 0.4836\n",
      "Epoch 115/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.5750 - accuracy: 0.5567 - val_loss: 1.9487 - val_accuracy: 0.4871\n",
      "Epoch 116/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.5682 - accuracy: 0.5586 - val_loss: 1.9452 - val_accuracy: 0.4886\n",
      "Epoch 117/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.5620 - accuracy: 0.5597 - val_loss: 1.9433 - val_accuracy: 0.4894\n",
      "Epoch 118/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.5557 - accuracy: 0.5610 - val_loss: 1.9418 - val_accuracy: 0.4894\n",
      "Epoch 119/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.5496 - accuracy: 0.5628 - val_loss: 1.9348 - val_accuracy: 0.4902\n",
      "Epoch 120/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.5435 - accuracy: 0.5646 - val_loss: 1.9346 - val_accuracy: 0.4925\n",
      "Epoch 121/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.5374 - accuracy: 0.5665 - val_loss: 1.9318 - val_accuracy: 0.4925\n",
      "Epoch 122/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.5313 - accuracy: 0.5667 - val_loss: 1.9275 - val_accuracy: 0.4917\n",
      "Epoch 123/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.5254 - accuracy: 0.5673 - val_loss: 1.9252 - val_accuracy: 0.4917\n",
      "Epoch 124/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.5191 - accuracy: 0.5691 - val_loss: 1.9243 - val_accuracy: 0.4917\n",
      "Epoch 125/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.5132 - accuracy: 0.5727 - val_loss: 1.9209 - val_accuracy: 0.4925\n",
      "Epoch 126/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.5076 - accuracy: 0.5726 - val_loss: 1.9182 - val_accuracy: 0.4940\n",
      "Epoch 127/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.5023 - accuracy: 0.5747 - val_loss: 1.9158 - val_accuracy: 0.4940\n",
      "Epoch 128/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.4959 - accuracy: 0.5753 - val_loss: 1.9115 - val_accuracy: 0.4948\n",
      "Epoch 129/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.4905 - accuracy: 0.5783 - val_loss: 1.9085 - val_accuracy: 0.4933\n",
      "Epoch 130/300\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 1.4848 - accuracy: 0.5784 - val_loss: 1.9086 - val_accuracy: 0.4921\n",
      "Epoch 131/300\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 1.4790 - accuracy: 0.5811 - val_loss: 1.9058 - val_accuracy: 0.4952\n",
      "Epoch 132/300\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 1.4739 - accuracy: 0.5812 - val_loss: 1.9035 - val_accuracy: 0.4944\n",
      "Epoch 133/300\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.4681 - accuracy: 0.5819 - val_loss: 1.9022 - val_accuracy: 0.4952\n",
      "Epoch 134/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.4627 - accuracy: 0.5838 - val_loss: 1.8982 - val_accuracy: 0.4963\n",
      "Epoch 135/300\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.4573 - accuracy: 0.5849 - val_loss: 1.8997 - val_accuracy: 0.4987\n",
      "Epoch 136/300\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.4519 - accuracy: 0.5871 - val_loss: 1.8965 - val_accuracy: 0.4990\n",
      "Epoch 137/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.4466 - accuracy: 0.5885 - val_loss: 1.8932 - val_accuracy: 0.4987\n",
      "Epoch 138/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.4414 - accuracy: 0.5899 - val_loss: 1.8934 - val_accuracy: 0.5017\n",
      "Epoch 139/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.4363 - accuracy: 0.5914 - val_loss: 1.8884 - val_accuracy: 0.4998\n",
      "Epoch 140/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.4309 - accuracy: 0.5934 - val_loss: 1.8907 - val_accuracy: 0.5048\n",
      "Epoch 141/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.4261 - accuracy: 0.5942 - val_loss: 1.8868 - val_accuracy: 0.5013\n",
      "Epoch 142/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.4208 - accuracy: 0.5959 - val_loss: 1.8834 - val_accuracy: 0.5037\n",
      "Epoch 143/300\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.4157 - accuracy: 0.5962 - val_loss: 1.8840 - val_accuracy: 0.5048\n",
      "Epoch 144/300\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 1.4111 - accuracy: 0.5981 - val_loss: 1.8836 - val_accuracy: 0.5075\n",
      "Epoch 145/300\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 1.4063 - accuracy: 0.5989 - val_loss: 1.8796 - val_accuracy: 0.5071\n",
      "Epoch 146/300\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 1.4011 - accuracy: 0.6005 - val_loss: 1.8792 - val_accuracy: 0.5071\n",
      "Epoch 147/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3966 - accuracy: 0.6016 - val_loss: 1.8774 - val_accuracy: 0.5110\n",
      "Epoch 148/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3912 - accuracy: 0.6021 - val_loss: 1.8800 - val_accuracy: 0.5079\n",
      "Epoch 149/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3865 - accuracy: 0.6042 - val_loss: 1.8753 - val_accuracy: 0.5102\n",
      "Epoch 150/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3816 - accuracy: 0.6062 - val_loss: 1.8743 - val_accuracy: 0.5121\n",
      "Epoch 151/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3772 - accuracy: 0.6054 - val_loss: 1.8718 - val_accuracy: 0.5102\n",
      "Epoch 152/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3722 - accuracy: 0.6083 - val_loss: 1.8724 - val_accuracy: 0.5114\n",
      "Epoch 153/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3674 - accuracy: 0.6097 - val_loss: 1.8699 - val_accuracy: 0.5144\n",
      "Epoch 154/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3631 - accuracy: 0.6113 - val_loss: 1.8712 - val_accuracy: 0.5141\n",
      "Epoch 155/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3587 - accuracy: 0.6098 - val_loss: 1.8679 - val_accuracy: 0.5148\n",
      "Epoch 156/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3544 - accuracy: 0.6131 - val_loss: 1.8689 - val_accuracy: 0.5141\n",
      "Epoch 157/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3496 - accuracy: 0.6128 - val_loss: 1.8638 - val_accuracy: 0.5160\n",
      "Epoch 158/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3450 - accuracy: 0.6142 - val_loss: 1.8654 - val_accuracy: 0.5160\n",
      "Epoch 159/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3407 - accuracy: 0.6143 - val_loss: 1.8657 - val_accuracy: 0.5152\n",
      "Epoch 160/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3363 - accuracy: 0.6155 - val_loss: 1.8640 - val_accuracy: 0.5156\n",
      "Epoch 161/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3323 - accuracy: 0.6179 - val_loss: 1.8607 - val_accuracy: 0.5125\n",
      "Epoch 162/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3280 - accuracy: 0.6192 - val_loss: 1.8612 - val_accuracy: 0.5160\n",
      "Epoch 163/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3234 - accuracy: 0.6177 - val_loss: 1.8595 - val_accuracy: 0.5156\n",
      "Epoch 164/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3191 - accuracy: 0.6200 - val_loss: 1.8592 - val_accuracy: 0.5148\n",
      "Epoch 165/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3154 - accuracy: 0.6217 - val_loss: 1.8559 - val_accuracy: 0.5171\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3109 - accuracy: 0.6224 - val_loss: 1.8584 - val_accuracy: 0.5148\n",
      "Epoch 167/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3063 - accuracy: 0.6243 - val_loss: 1.8576 - val_accuracy: 0.5156\n",
      "Epoch 168/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.3026 - accuracy: 0.6250 - val_loss: 1.8582 - val_accuracy: 0.5191\n",
      "Epoch 169/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2984 - accuracy: 0.6269 - val_loss: 1.8552 - val_accuracy: 0.5171\n",
      "Epoch 170/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2947 - accuracy: 0.6263 - val_loss: 1.8544 - val_accuracy: 0.5179\n",
      "Epoch 171/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2902 - accuracy: 0.6290 - val_loss: 1.8560 - val_accuracy: 0.5187\n",
      "Epoch 172/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2861 - accuracy: 0.6300 - val_loss: 1.8544 - val_accuracy: 0.5171\n",
      "Epoch 173/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2824 - accuracy: 0.6305 - val_loss: 1.8544 - val_accuracy: 0.5183\n",
      "Epoch 174/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2785 - accuracy: 0.6311 - val_loss: 1.8548 - val_accuracy: 0.5198\n",
      "Epoch 175/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2744 - accuracy: 0.6339 - val_loss: 1.8536 - val_accuracy: 0.5198\n",
      "Epoch 176/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2706 - accuracy: 0.6338 - val_loss: 1.8526 - val_accuracy: 0.5202\n",
      "Epoch 177/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2668 - accuracy: 0.6339 - val_loss: 1.8500 - val_accuracy: 0.5191\n",
      "Epoch 178/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2626 - accuracy: 0.6348 - val_loss: 1.8518 - val_accuracy: 0.5187\n",
      "Epoch 179/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2591 - accuracy: 0.6354 - val_loss: 1.8499 - val_accuracy: 0.5202\n",
      "Epoch 180/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2550 - accuracy: 0.6369 - val_loss: 1.8509 - val_accuracy: 0.5191\n",
      "Epoch 181/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2515 - accuracy: 0.6380 - val_loss: 1.8502 - val_accuracy: 0.5210\n",
      "Epoch 182/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2475 - accuracy: 0.6390 - val_loss: 1.8494 - val_accuracy: 0.5214\n",
      "Epoch 183/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2439 - accuracy: 0.6395 - val_loss: 1.8494 - val_accuracy: 0.5221\n",
      "Epoch 184/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2402 - accuracy: 0.6409 - val_loss: 1.8516 - val_accuracy: 0.5214\n",
      "Epoch 185/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2366 - accuracy: 0.6401 - val_loss: 1.8469 - val_accuracy: 0.5233\n",
      "Epoch 186/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2329 - accuracy: 0.6421 - val_loss: 1.8478 - val_accuracy: 0.5237\n",
      "Epoch 187/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2292 - accuracy: 0.6425 - val_loss: 1.8483 - val_accuracy: 0.5271\n",
      "Epoch 188/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2254 - accuracy: 0.6452 - val_loss: 1.8467 - val_accuracy: 0.5241\n",
      "Epoch 189/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2220 - accuracy: 0.6449 - val_loss: 1.8473 - val_accuracy: 0.5252\n",
      "Epoch 190/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2185 - accuracy: 0.6457 - val_loss: 1.8515 - val_accuracy: 0.5229\n",
      "Epoch 191/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2149 - accuracy: 0.6471 - val_loss: 1.8490 - val_accuracy: 0.5264\n",
      "Epoch 192/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2115 - accuracy: 0.6474 - val_loss: 1.8474 - val_accuracy: 0.5279\n",
      "Epoch 193/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2076 - accuracy: 0.6484 - val_loss: 1.8462 - val_accuracy: 0.5248\n",
      "Epoch 194/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2042 - accuracy: 0.6492 - val_loss: 1.8476 - val_accuracy: 0.5252\n",
      "Epoch 195/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.2004 - accuracy: 0.6504 - val_loss: 1.8506 - val_accuracy: 0.5256\n",
      "Epoch 196/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1971 - accuracy: 0.6507 - val_loss: 1.8499 - val_accuracy: 0.5256\n",
      "Epoch 197/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1937 - accuracy: 0.6518 - val_loss: 1.8477 - val_accuracy: 0.5256\n",
      "Epoch 198/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1903 - accuracy: 0.6536 - val_loss: 1.8509 - val_accuracy: 0.5275\n",
      "Epoch 199/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1870 - accuracy: 0.6537 - val_loss: 1.8478 - val_accuracy: 0.5264\n",
      "Epoch 200/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1837 - accuracy: 0.6537 - val_loss: 1.8507 - val_accuracy: 0.5268\n",
      "Epoch 201/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1800 - accuracy: 0.6568 - val_loss: 1.8511 - val_accuracy: 0.5256\n",
      "Epoch 202/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1768 - accuracy: 0.6579 - val_loss: 1.8516 - val_accuracy: 0.5264\n",
      "Epoch 203/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1736 - accuracy: 0.6585 - val_loss: 1.8503 - val_accuracy: 0.5260\n",
      "Epoch 204/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1704 - accuracy: 0.6584 - val_loss: 1.8509 - val_accuracy: 0.5283\n",
      "Epoch 205/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1670 - accuracy: 0.6597 - val_loss: 1.8534 - val_accuracy: 0.5256\n",
      "Epoch 206/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1639 - accuracy: 0.6612 - val_loss: 1.8507 - val_accuracy: 0.5268\n",
      "Epoch 207/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1603 - accuracy: 0.6618 - val_loss: 1.8535 - val_accuracy: 0.5279\n",
      "Epoch 208/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1574 - accuracy: 0.6640 - val_loss: 1.8525 - val_accuracy: 0.5283\n",
      "Epoch 209/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1539 - accuracy: 0.6645 - val_loss: 1.8531 - val_accuracy: 0.5256\n",
      "Epoch 210/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1509 - accuracy: 0.6650 - val_loss: 1.8549 - val_accuracy: 0.5237\n",
      "Epoch 211/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1477 - accuracy: 0.6656 - val_loss: 1.8497 - val_accuracy: 0.5279\n",
      "Epoch 212/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1443 - accuracy: 0.6655 - val_loss: 1.8542 - val_accuracy: 0.5252\n",
      "Epoch 213/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1413 - accuracy: 0.6659 - val_loss: 1.8534 - val_accuracy: 0.5241\n",
      "Epoch 214/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1384 - accuracy: 0.6694 - val_loss: 1.8565 - val_accuracy: 0.5295\n",
      "Epoch 215/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1351 - accuracy: 0.6694 - val_loss: 1.8534 - val_accuracy: 0.5256\n",
      "Epoch 216/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1321 - accuracy: 0.6712 - val_loss: 1.8559 - val_accuracy: 0.5287\n",
      "Epoch 217/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1291 - accuracy: 0.6702 - val_loss: 1.8550 - val_accuracy: 0.5271\n",
      "Epoch 218/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1259 - accuracy: 0.6728 - val_loss: 1.8591 - val_accuracy: 0.5252\n",
      "Epoch 219/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1227 - accuracy: 0.6727 - val_loss: 1.8571 - val_accuracy: 0.5260\n",
      "Epoch 220/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1197 - accuracy: 0.6722 - val_loss: 1.8568 - val_accuracy: 0.5237\n",
      "Epoch 221/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1169 - accuracy: 0.6752 - val_loss: 1.8598 - val_accuracy: 0.5260\n",
      "Epoch 222/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1137 - accuracy: 0.6759 - val_loss: 1.8594 - val_accuracy: 0.5271\n",
      "Epoch 223/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1108 - accuracy: 0.6762 - val_loss: 1.8595 - val_accuracy: 0.5279\n",
      "Epoch 224/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1079 - accuracy: 0.6771 - val_loss: 1.8592 - val_accuracy: 0.5295\n",
      "Epoch 225/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1050 - accuracy: 0.6785 - val_loss: 1.8632 - val_accuracy: 0.5241\n",
      "Epoch 226/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.1019 - accuracy: 0.6792 - val_loss: 1.8624 - val_accuracy: 0.5264\n",
      "Epoch 227/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0988 - accuracy: 0.6811 - val_loss: 1.8638 - val_accuracy: 0.5283\n",
      "Epoch 228/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0959 - accuracy: 0.6816 - val_loss: 1.8626 - val_accuracy: 0.5264\n",
      "Epoch 229/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0934 - accuracy: 0.6801 - val_loss: 1.8638 - val_accuracy: 0.5287\n",
      "Epoch 230/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0904 - accuracy: 0.6826 - val_loss: 1.8658 - val_accuracy: 0.5275\n",
      "Epoch 231/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0876 - accuracy: 0.6848 - val_loss: 1.8661 - val_accuracy: 0.5283\n",
      "Epoch 232/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0852 - accuracy: 0.6848 - val_loss: 1.8682 - val_accuracy: 0.5298\n",
      "Epoch 233/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0821 - accuracy: 0.6869 - val_loss: 1.8646 - val_accuracy: 0.5291\n",
      "Epoch 234/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0791 - accuracy: 0.6876 - val_loss: 1.8674 - val_accuracy: 0.5271\n",
      "Epoch 235/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0765 - accuracy: 0.6881 - val_loss: 1.8666 - val_accuracy: 0.5248\n",
      "Epoch 236/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0737 - accuracy: 0.6896 - val_loss: 1.8668 - val_accuracy: 0.5295\n",
      "Epoch 237/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0707 - accuracy: 0.6898 - val_loss: 1.8687 - val_accuracy: 0.5291\n",
      "Epoch 238/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0678 - accuracy: 0.6900 - val_loss: 1.8698 - val_accuracy: 0.5295\n",
      "Epoch 239/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0654 - accuracy: 0.6930 - val_loss: 1.8712 - val_accuracy: 0.5306\n",
      "Epoch 240/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0626 - accuracy: 0.6925 - val_loss: 1.8727 - val_accuracy: 0.5275\n",
      "Epoch 241/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0600 - accuracy: 0.6935 - val_loss: 1.8742 - val_accuracy: 0.5295\n",
      "Epoch 242/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0572 - accuracy: 0.6948 - val_loss: 1.8758 - val_accuracy: 0.5325\n",
      "Epoch 243/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0540 - accuracy: 0.6951 - val_loss: 1.8753 - val_accuracy: 0.5291\n",
      "Epoch 244/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0517 - accuracy: 0.6962 - val_loss: 1.8744 - val_accuracy: 0.5306\n",
      "Epoch 245/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0486 - accuracy: 0.6959 - val_loss: 1.8792 - val_accuracy: 0.5271\n",
      "Epoch 246/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0466 - accuracy: 0.6968 - val_loss: 1.8765 - val_accuracy: 0.5291\n",
      "Epoch 247/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0438 - accuracy: 0.6972 - val_loss: 1.8822 - val_accuracy: 0.5287\n",
      "Epoch 248/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0415 - accuracy: 0.7001 - val_loss: 1.8787 - val_accuracy: 0.5306\n",
      "Epoch 249/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0385 - accuracy: 0.6994 - val_loss: 1.8830 - val_accuracy: 0.5310\n",
      "Epoch 250/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0359 - accuracy: 0.7004 - val_loss: 1.8836 - val_accuracy: 0.5279\n",
      "Epoch 251/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0335 - accuracy: 0.7023 - val_loss: 1.8836 - val_accuracy: 0.5310\n",
      "Epoch 252/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0314 - accuracy: 0.7025 - val_loss: 1.8841 - val_accuracy: 0.5310\n",
      "Epoch 253/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0283 - accuracy: 0.7024 - val_loss: 1.8847 - val_accuracy: 0.5318\n",
      "Epoch 254/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0255 - accuracy: 0.7042 - val_loss: 1.8869 - val_accuracy: 0.5314\n",
      "Epoch 255/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0238 - accuracy: 0.7051 - val_loss: 1.8869 - val_accuracy: 0.5310\n",
      "Epoch 256/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0204 - accuracy: 0.7060 - val_loss: 1.8884 - val_accuracy: 0.5318\n",
      "Epoch 257/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0188 - accuracy: 0.7047 - val_loss: 1.8875 - val_accuracy: 0.5329\n",
      "Epoch 258/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0156 - accuracy: 0.7065 - val_loss: 1.8924 - val_accuracy: 0.5306\n",
      "Epoch 259/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0134 - accuracy: 0.7080 - val_loss: 1.8926 - val_accuracy: 0.5314\n",
      "Epoch 260/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0111 - accuracy: 0.7075 - val_loss: 1.8934 - val_accuracy: 0.5341\n",
      "Epoch 261/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0082 - accuracy: 0.7082 - val_loss: 1.8932 - val_accuracy: 0.5337\n",
      "Epoch 262/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0061 - accuracy: 0.7090 - val_loss: 1.8972 - val_accuracy: 0.5329\n",
      "Epoch 263/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0036 - accuracy: 0.7099 - val_loss: 1.8966 - val_accuracy: 0.5322\n",
      "Epoch 264/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 1.0012 - accuracy: 0.7112 - val_loss: 1.9018 - val_accuracy: 0.5337\n",
      "Epoch 265/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9987 - accuracy: 0.7116 - val_loss: 1.8997 - val_accuracy: 0.5322\n",
      "Epoch 266/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9961 - accuracy: 0.7122 - val_loss: 1.9006 - val_accuracy: 0.5322\n",
      "Epoch 267/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9937 - accuracy: 0.7136 - val_loss: 1.9050 - val_accuracy: 0.5337\n",
      "Epoch 268/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9914 - accuracy: 0.7138 - val_loss: 1.9029 - val_accuracy: 0.5329\n",
      "Epoch 269/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9891 - accuracy: 0.7132 - val_loss: 1.9054 - val_accuracy: 0.5302\n",
      "Epoch 270/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9864 - accuracy: 0.7168 - val_loss: 1.9038 - val_accuracy: 0.5333\n",
      "Epoch 271/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9843 - accuracy: 0.7160 - val_loss: 1.9087 - val_accuracy: 0.5352\n",
      "Epoch 272/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9820 - accuracy: 0.7157 - val_loss: 1.9054 - val_accuracy: 0.5329\n",
      "Epoch 273/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9795 - accuracy: 0.7172 - val_loss: 1.9117 - val_accuracy: 0.5333\n",
      "Epoch 274/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9769 - accuracy: 0.7160 - val_loss: 1.9096 - val_accuracy: 0.5352\n",
      "Epoch 275/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9752 - accuracy: 0.7199 - val_loss: 1.9117 - val_accuracy: 0.5333\n",
      "Epoch 276/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9729 - accuracy: 0.7198 - val_loss: 1.9149 - val_accuracy: 0.5318\n",
      "Epoch 277/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9701 - accuracy: 0.7182 - val_loss: 1.9142 - val_accuracy: 0.5329\n",
      "Epoch 278/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9683 - accuracy: 0.7190 - val_loss: 1.9168 - val_accuracy: 0.5360\n",
      "Epoch 279/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9660 - accuracy: 0.7216 - val_loss: 1.9209 - val_accuracy: 0.5352\n",
      "Epoch 280/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9632 - accuracy: 0.7209 - val_loss: 1.9216 - val_accuracy: 0.5337\n",
      "Epoch 281/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9613 - accuracy: 0.7211 - val_loss: 1.9199 - val_accuracy: 0.5329\n",
      "Epoch 282/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9591 - accuracy: 0.7235 - val_loss: 1.9244 - val_accuracy: 0.5333\n",
      "Epoch 283/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9571 - accuracy: 0.7231 - val_loss: 1.9293 - val_accuracy: 0.5352\n",
      "Epoch 284/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9541 - accuracy: 0.7239 - val_loss: 1.9258 - val_accuracy: 0.5372\n",
      "Epoch 285/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9523 - accuracy: 0.7245 - val_loss: 1.9251 - val_accuracy: 0.5356\n",
      "Epoch 286/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9499 - accuracy: 0.7257 - val_loss: 1.9280 - val_accuracy: 0.5360\n",
      "Epoch 287/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9475 - accuracy: 0.7259 - val_loss: 1.9308 - val_accuracy: 0.5348\n",
      "Epoch 288/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9457 - accuracy: 0.7262 - val_loss: 1.9318 - val_accuracy: 0.5372\n",
      "Epoch 289/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9436 - accuracy: 0.7260 - val_loss: 1.9349 - val_accuracy: 0.5375\n",
      "Epoch 290/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9414 - accuracy: 0.7270 - val_loss: 1.9345 - val_accuracy: 0.5391\n",
      "Epoch 291/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9392 - accuracy: 0.7295 - val_loss: 1.9344 - val_accuracy: 0.5379\n",
      "Epoch 292/300\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.9375 - accuracy: 0.7277 - val_loss: 1.9409 - val_accuracy: 0.5364\n",
      "Epoch 293/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9348 - accuracy: 0.7295 - val_loss: 1.9382 - val_accuracy: 0.5379\n",
      "Epoch 294/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9329 - accuracy: 0.7287 - val_loss: 1.9407 - val_accuracy: 0.5383\n",
      "Epoch 295/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9308 - accuracy: 0.7311 - val_loss: 1.9445 - val_accuracy: 0.5383\n",
      "Epoch 296/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9283 - accuracy: 0.7311 - val_loss: 1.9451 - val_accuracy: 0.5383\n",
      "Epoch 297/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9262 - accuracy: 0.7311 - val_loss: 1.9479 - val_accuracy: 0.5379\n",
      "Epoch 298/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9243 - accuracy: 0.7316 - val_loss: 1.9497 - val_accuracy: 0.5364\n",
      "Epoch 299/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9217 - accuracy: 0.7339 - val_loss: 1.9471 - val_accuracy: 0.5395\n",
      "Epoch 300/300\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.9201 - accuracy: 0.7346 - val_loss: 1.9504 - val_accuracy: 0.5391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0d2bb45650>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Input(192),\n",
    "                                    tf.keras.layers.Dense(100, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(50, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(25, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(80, activation=tf.nn.softmax)])\n",
    "lr= tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.0001,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.95,\n",
    "    staircase=True)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=tf.optimizers.Adam(learning_rate=lr), metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(train, train_y, batch_size=128, epochs=300, validation_data=(val, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed67373",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e089127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2597, 80)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb717a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.9023841e-14, 2.1066073e-13, 1.1902239e-04, ..., 1.4169917e-04,\n",
       "        8.0033584e-04, 1.0981495e-04],\n",
       "       [1.4460075e-03, 3.9155670e-02, 1.2518999e-03, ..., 4.4073397e-03,\n",
       "        4.5355261e-04, 6.9673844e-03],\n",
       "       [2.9226914e-07, 1.7533808e-06, 1.5676622e-03, ..., 3.9922643e-02,\n",
       "        2.7641291e-03, 1.8937675e-02],\n",
       "       ...,\n",
       "       [1.9470069e-14, 3.9199704e-01, 8.6634760e-10, ..., 2.5676108e-09,\n",
       "        5.5166267e-14, 4.6950288e-10],\n",
       "       [6.3872412e-03, 2.1324426e-02, 5.5265869e-04, ..., 2.6160762e-07,\n",
       "        6.5091066e-09, 3.1180056e-07],\n",
       "       [2.5853403e-22, 2.8989339e-31, 1.6093675e-10, ..., 1.0195894e-07,\n",
       "        1.8279170e-06, 3.1377755e-07]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c61b6a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2597, 80)\n",
      "(2597, 80)\n"
     ]
    }
   ],
   "source": [
    "print(test_y.shape)\n",
    "print(y_pred.shape)\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "y_test=np.argmax(test_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b373802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1853624775845376"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d97a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
