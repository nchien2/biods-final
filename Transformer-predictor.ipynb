{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cheap-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "simple-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('mouse1sample1.hdf5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "biological-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate \n",
    "genes = set()\n",
    "annotated_cells = []\n",
    "annotations = []\n",
    "\n",
    "for cell_id in f['cells']:\n",
    "    cell = f['cells'][cell_id]\n",
    "    ann = dict(cell.attrs)['annotation']\n",
    "    if ann != 'unannotated':\n",
    "        annotated_cells.append(cell_id)\n",
    "        annotations.append(ann)\n",
    "    for z in cell.attrs['zslices']:\n",
    "        spot_genes = cell['spot_genes'][z]\n",
    "        genes.update(set(spot_genes))\n",
    "annotations_count = Counter(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "national-column",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Annotated Samples: 18453\n",
      "Num of Cell Types: 93\n",
      "Max Number of Samples per Cell Type: 2136\n",
      "Min Number of Samples per Cell Type: 1\n",
      "Average Number of Samples per Cell Type: 198.41935483870967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 93 artists>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Number of Annotated Samples:\", len(annotated_cells))\n",
    "print(\"Num of Cell Types:\", len(annotations_count))\n",
    "print(\"Max Number of Samples per Cell Type:\", max(annotations_count.values()))\n",
    "print(\"Min Number of Samples per Cell Type:\", min(annotations_count.values()))\n",
    "print(\"Average Number of Samples per Cell Type:\", sum(annotations_count.values())/93)\n",
    "\n",
    "#graph of num of samples across cell-types \n",
    "plt.bar(np.arange(0,93), annotations_count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab31f88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:36: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18453, 1682, 3)\n"
     ]
    }
   ],
   "source": [
    "# Long processing step to extract coordinates and genes, run only once\n",
    "\n",
    "maxlen = 1682\n",
    "data_coords = []\n",
    "data_genes = []\n",
    "gene_indices = {k: v for v, k in enumerate(set(genes))}\n",
    "\n",
    "for cell_id in annotated_cells:\n",
    "    cell_coords = []\n",
    "    cell_genes = []\n",
    "    cell = f['cells'][cell_id]\n",
    "    keys = list(cell['boundaries'].keys())\n",
    "    \n",
    "    for z in cell.attrs['zslices']:   \n",
    "        spot_coords = cell['spot_coords'][z]\n",
    "        spot_genes = cell['spot_genes'][z]\n",
    "        \n",
    "        cell_coords += list(spot_coords)\n",
    "        cell_genes += [gene_indices[gene] for gene in list(spot_genes)]\n",
    "        \n",
    "    z = keys[int(len(keys)/2)]\n",
    "    boundary = cell['boundaries'][z]\n",
    "     \n",
    "    cell_coords += list(boundary)\n",
    "    cell_genes += [-1] * len(boundary)\n",
    "    \n",
    "    data_coords.append(cell_coords)\n",
    "    data_genes.append(cell_genes)\n",
    "\n",
    "\n",
    "data_coords = keras.preprocessing.sequence.pad_sequences(np.array(data_coords), maxlen = maxlen)\n",
    "data_genes = np.expand_dims(keras.preprocessing.sequence.pad_sequences(np.array(data_genes), maxlen=maxlen), axis=-1)\n",
    "\n",
    "data = np.concatenate([data_coords, data_genes], axis=-1)\n",
    "print(data.shape)\n",
    "np.save('data.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f3bcf8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18453, 1682, 3)\n"
     ]
    }
   ],
   "source": [
    "with open('data.npy', 'rb') as f:\n",
    "    data = np.load(f)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "continued-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating one-hot coded vectors for cell-type (labels for multi)\n",
    "annotation_indices = {k: v for v, k in enumerate(list(annotations_count.keys()))}\n",
    "labels = np.zeros((len(annotated_cells), len(annotation_indices)))\n",
    "for index in range(len(annotated_cells)):\n",
    "    cell = f['cells'][annotated_cells[index]]\n",
    "    ann = dict(cell.attrs)['annotation']\n",
    "    arr_index = annotation_indices[ann]\n",
    "    labels[index][arr_index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2331cc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682\n"
     ]
    }
   ],
   "source": [
    "maxlen = 0\n",
    "for ex in data:\n",
    "    if len(ex[1]) > maxlen:\n",
    "        maxlen = len(ex[1])\n",
    "print(maxlen)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "51a69de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12917, 1682, 3) (12917, 93)\n",
      "(2768, 1682, 3) (2768, 93)\n",
      "(2768, 1682, 3) (2768, 93)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test, train_y, test_y = train_test_split(data, labels, test_size=0.3)\n",
    "test, val, test_y, val_y = train_test_split(test, test_y, test_size=0.5)\n",
    "\n",
    "val = keras.preprocessing.sequence.pad_sequences(val, maxlen=maxlen)\n",
    "test = keras.preprocessing.sequence.pad_sequences(test, maxlen=maxlen)\n",
    "\n",
    "print(train.shape, train_y.shape)\n",
    "print(val.shape, val_y.shape)\n",
    "print(test.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "575ec178",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a7f9e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, coord_size, vocab_size, embed_dim):\n",
    "        super(GeneAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.x_emb = layers.Embedding(input_dim=coord_size, output_dim=embed_dim)\n",
    "        self.y_emb = layers.Embedding(input_dim=coord_size, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        xcoord = self.x_emb(x[:,:,0])\n",
    "        ycoord = self.y_emb(x[:,:,1])\n",
    "        genes = self.token_emb(x[:,:,-1])\n",
    "        return xcoord + ycoord + genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3cabc0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary code to get coord_size for use in the embedding layer (found to be 10880)\n",
    "\n",
    "# min = 0\n",
    "# max = 0\n",
    "\n",
    "# for point in data:\n",
    "#     for coord in point:\n",
    "#         if coord[0] > max:\n",
    "#             max = coord[0]\n",
    "#         if coord[0] < min:\n",
    "#             min = coord[0]\n",
    "            \n",
    "#         if coord[1] > max:\n",
    "#             max = coord[1]\n",
    "#         if coord[1] < min:\n",
    "#             min = coord[1]\n",
    "    \n",
    "# print(min)\n",
    "# print(max)\n",
    "# print(max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d1f69e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 32  # Embedding size for each token\n",
    "num_heads = 3  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "vocab_size = len(genes) + 1\n",
    "coord_size = 10880\n",
    "\n",
    "inputs = layers.Input(shape=(maxlen,3))\n",
    "embedding_layer = GeneAndPositionEmbedding(coord_size, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(93, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7034f447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "404/404 [==============================] - 123s 301ms/step - loss: 3.0467 - accuracy: 0.2593 - val_loss: 1.6231 - val_accuracy: 0.6022\n",
      "Epoch 2/10\n",
      "404/404 [==============================] - 121s 300ms/step - loss: 1.3710 - accuracy: 0.6458 - val_loss: 1.1203 - val_accuracy: 0.6998\n",
      "Epoch 3/10\n",
      "404/404 [==============================] - 121s 301ms/step - loss: 1.0022 - accuracy: 0.7263 - val_loss: 1.0474 - val_accuracy: 0.7124\n",
      "Epoch 4/10\n",
      "404/404 [==============================] - 120s 298ms/step - loss: 0.8124 - accuracy: 0.7667 - val_loss: 1.0378 - val_accuracy: 0.7222\n",
      "Epoch 5/10\n",
      "404/404 [==============================] - 120s 297ms/step - loss: 0.6981 - accuracy: 0.7959 - val_loss: 1.0600 - val_accuracy: 0.7207\n",
      "Epoch 6/10\n",
      "404/404 [==============================] - 121s 298ms/step - loss: 0.6000 - accuracy: 0.8236 - val_loss: 1.0630 - val_accuracy: 0.7399\n",
      "Epoch 7/10\n",
      "404/404 [==============================] - 120s 298ms/step - loss: 0.5341 - accuracy: 0.8382 - val_loss: 1.0760 - val_accuracy: 0.7417\n",
      "Epoch 8/10\n",
      "404/404 [==============================] - 121s 300ms/step - loss: 0.4980 - accuracy: 0.8473 - val_loss: 1.1836 - val_accuracy: 0.7334\n",
      "Epoch 9/10\n",
      "404/404 [==============================] - 120s 298ms/step - loss: 0.4579 - accuracy: 0.8579 - val_loss: 1.1385 - val_accuracy: 0.7384\n",
      "Epoch 10/10\n",
      "404/404 [==============================] - 120s 297ms/step - loss: 0.4167 - accuracy: 0.8712 - val_loss: 1.1568 - val_accuracy: 0.7417\n"
     ]
    }
   ],
   "source": [
    "#TODO: Prevent overfitting, experiment with learning rate\n",
    "# lr= tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     0.0001,\n",
    "#     decay_steps=100000,\n",
    "#     decay_rate=0.95,\n",
    "#     staircase=True)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    train, train_y, batch_size=32, epochs=10, validation_data=(val, val_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b110bff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 111ms/step - loss: 0.5033 - accuracy: 0.8689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5032734274864197, 0.8688583970069885]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
