{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e431d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a46f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = h5py.File('mouse1sample1.hdf5','r')\n",
    "# p_scores = pd.read_csv('merfish_M1S1_filtered_periph_scores.csv')\n",
    "# p_scores = p_scores.loc[p_scores['annotation'] != 'unannotated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8925e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # time intensive step: get list of annotated cell_ids and annotation types \n",
    "# annotated_cells = []\n",
    "# annotations = []\n",
    "# for cell_id in f['cells']:\n",
    "#     cell = f['cells'][cell_id]\n",
    "#     ann = dict(cell.attrs)['annotation']\n",
    "#     if ann != 'unannotated' and cell_id in list(p_scores['cell_id']):\n",
    "#         annotated_cells.append(cell_id)\n",
    "#         annotations.append(ann)\n",
    "        \n",
    "# annotations_count = Counter(annotations)\n",
    "# print(\"Number of Annotated Samples:\", len(annotated_cells))\n",
    "# print(\"Num of Cell Types:\", len(annotations_count))\n",
    "# print(\"Max Number of Samples per Cell Type:\", max(annotations_count.values()))\n",
    "# print(\"Min Number of Samples per Cell Type:\", min(annotations_count.values()))\n",
    "# print(\"Average Number of Samples per Cell Type:\", sum(annotations_count.values())/93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bbac2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# periphery data: shape (len(annotated_cells), num_genes)\n",
    "# num_genes = (p_scores['gene']).unique().shape[0]\n",
    "# cell_indices = {k: v for v, k in enumerate(list(p_scores['cell_id'].unique()))}\n",
    "# gene_indices = {k: v for v, k in enumerate(list(p_scores['gene'].unique()))}\n",
    "\n",
    "# periphery_data = np.zeros((len(annotated_cells), num_genes))\n",
    "# for cell_id in annotated_cells:\n",
    "#     subset = p_scores.loc[p_scores['cell_id'] == cell_id]\n",
    "#     for index, s in subset.iterrows():\n",
    "#         cell_index = cell_indices[cell_id]\n",
    "#         gene_index = gene_indices[s['gene']]\n",
    "#         periphery_data[cell_index][gene_index] = s['periphery_score']\n",
    "\n",
    "# remove outlier genes\n",
    "# expr = np.sum(np.square(periphery_data), axis=0)\n",
    "# periphery_data = periphery_data[:,np.logical_and(expr >= np.percentile(expr, 1), expr <= np.percentile(expr, 99))]\n",
    "# cv = np.std(periphery_data, axis=0) / np.mean(periphery_data, axis=0)\n",
    "# periphery_data = periphery_data[:,np.logical_and(cv >= np.percentile(cv, 1), cv <= np.percentile(cv, 99))]\n",
    "# np.save('periphery_data', periphery_data)\n",
    "\n",
    "periphery_data = np.load('periphery_data.npy')\n",
    "\n",
    "# remove outlier genes\n",
    "expr = np.sum(np.square(periphery_data), axis=0)\n",
    "periphery_data = periphery_data[:,np.logical_and(expr >= np.percentile(expr, 1), expr <= np.percentile(expr, 99))]\n",
    "cv = np.std(periphery_data, axis=0) / np.mean(periphery_data, axis=0)\n",
    "periphery_data = periphery_data[:,np.logical_and(cv >= np.percentile(cv, 1), cv <= np.percentile(cv, 99))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5305c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #image data: shape (len(annotated_cells), 224, 224))\n",
    "# image_data = np.zeros(shape=(len(annotated_cells), 224, 224)).astype('uint8')\n",
    "# fig = plt.figure(figsize=(4, 4), dpi=56)\n",
    "# plt.gray()\n",
    "# idx = 0\n",
    "# for cell_id in annotated_cells:\n",
    "#     cell = f['cells'][cell_id]\n",
    "#     keys = list(cell['boundaries'].keys())\n",
    "#     midpoint = keys[int(len(keys)/2)]\n",
    "#     boundary = cell['boundaries'][midpoint]\n",
    "#     xs = boundary[:,0]\n",
    "#     ys = boundary[:,1]\n",
    "#     plt.plot(xs,ys)\n",
    "#     plt.axis('equal')\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "#     fig.canvas.draw()\n",
    "#     fig_array = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "#     fig_array = fig_array.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "#     image_data[idx] = fig_array[:,:,0].astype('uint8')\n",
    "#     idx += 1\n",
    "#     plt.clf()\n",
    "#     print(f\"\\r{idx}\", end=\"\")\n",
    "  \n",
    "# print(image_data.shape)\n",
    "# np.save('image_data', image_data)\n",
    "\n",
    "image_data = np.load('image_data.npy')\n",
    "image_data = np.repeat(image_data[..., np.newaxis], 3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5540119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17312, 80)\n"
     ]
    }
   ],
   "source": [
    "# one hot encoded label vectors\n",
    "# annotation_indices = {k: v for v, k in enumerate(list(annotations_count.keys()))}\n",
    "# labels = np.zeros((len(annotated_cells), len(annotation_indices)))\n",
    "# for index in range(0, len(annotated_cells)):\n",
    "#     cell = f['cells'][annotated_cells[index]]\n",
    "#     ann = dict(cell.attrs)['annotation']\n",
    "#     arr_index = annotation_indices[ann]\n",
    "#     labels[index][arr_index] = 1\n",
    "# print(labels.shape)\n",
    "# np.save('labels', labels)\n",
    "\n",
    "labels = np.load('labels.npy')\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f371a035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12118, 224, 224, 3) (12118, 184) (12118, 80)\n",
      "(2597, 224, 224, 3) (2597, 184) (2597, 80)\n",
      "(2597, 224, 224, 3) (2597, 184) (2597, 80)\n"
     ]
    }
   ],
   "source": [
    "indices = [x for x in range(labels.shape[0])]\n",
    "train_indices, test = train_test_split(indices, test_size=0.3)\n",
    "test_indices, val_indices = train_test_split(test, test_size=0.5)\n",
    "\n",
    "image_train, periphery_train, labels_train = image_data[train_indices], periphery_data[train_indices], labels[train_indices]\n",
    "image_test, periphery_test, labels_test = image_data[test_indices], periphery_data[test_indices], labels[test_indices]\n",
    "image_val, periphery_val, labels_val = image_data[val_indices], periphery_data[val_indices], labels[val_indices]\n",
    "\n",
    "print(image_train.shape, periphery_train.shape, labels_train.shape)\n",
    "print(image_test.shape, periphery_test.shape, labels_test.shape)\n",
    "print(image_val.shape, periphery_val.shape, labels_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63520aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing individual models + late fusion model\n",
    "class WeightedAverage(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, n_output):\n",
    "        super(WeightedAverage, self).__init__()\n",
    "        self.W = tf.Variable(initial_value=tf.random.uniform(shape=[1,1,n_output], minval=0, maxval=1),\n",
    "            trainable=True) # (1,1,n_inputs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        # inputs is a list of tensor of shape [(n_batch, n_feat), ..., (n_batch, n_feat)]\n",
    "        # expand last dim of each input passed [(n_batch, n_feat, 1), ..., (n_batch, n_feat, 1)]\n",
    "        inputs = [tf.expand_dims(i, -1) for i in inputs]\n",
    "        inputs = tf.keras.layers.concatenate(axis=-1)(inputs) # (n_batch, n_feat, n_inputs)\n",
    "        weights = tf.nn.softmax(self.W, axis=-1) # (1,1,n_inputs)\n",
    "        # weights sum up to one on last dim\n",
    "        return tf.reduce_sum(weights*inputs, axis=-1) # (n_batch, n_feat)\n",
    "    \n",
    "periphery_model = tf.keras.models.Sequential([tf.keras.layers.Input(periphery_data.shape[1]),\n",
    "                                    tf.keras.layers.Dense(100, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(50, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(25, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(80, activation=tf.nn.softmax)])\n",
    "\n",
    "image_model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(32,(3,3),padding='same', activation='relu',input_shape=(224, 224, 3)),\n",
    "                                    tf.keras.layers.MaxPool2D((2,2)), \n",
    "                                    tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dropout(0.9),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(80, activation=tf.nn.softmax)])\n",
    "\n",
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(WeightedAverage(periphery_model.output, image_model.output))\n",
    "# # weighted_average = tf.keras.layers.concatenate([tf.multiply(periphery_model.output, 0.1), tf.multiply(image_model.output, 0.1)], axis=0)\n",
    "# # WA = WeightedAverage(n_output = 2)([periphery_model.output, image_model.output])\n",
    "# # model = tf.keras.models.Model(inputs=[periphery_model.input, image_model.input], outputs = WA)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7abbc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compiling late fusion model with exponential decay lr\n",
    "lr= tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.0001,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.95,\n",
    "    staircase=True)\n",
    "\n",
    "# early stopping to prevent overfitting \n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "periphery_model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=['accuracy'])\n",
    "# image_model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37c1a439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "379/379 [==============================] - 2s 4ms/step - loss: 4.3058 - accuracy: 0.0353 - val_loss: 4.1105 - val_accuracy: 0.0608\n",
      "Epoch 2/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 3.7405 - accuracy: 0.1033 - val_loss: 3.5343 - val_accuracy: 0.1171\n",
      "Epoch 3/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 3.4783 - accuracy: 0.1192 - val_loss: 3.4443 - val_accuracy: 0.1290\n",
      "Epoch 4/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 3.4050 - accuracy: 0.1708 - val_loss: 3.3782 - val_accuracy: 0.1941\n",
      "Epoch 5/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 3.3348 - accuracy: 0.2069 - val_loss: 3.3054 - val_accuracy: 0.2126\n",
      "Epoch 6/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 3.2586 - accuracy: 0.2139 - val_loss: 3.2302 - val_accuracy: 0.2141\n",
      "Epoch 7/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 3.1823 - accuracy: 0.2174 - val_loss: 3.1561 - val_accuracy: 0.2229\n",
      "Epoch 8/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 3.1077 - accuracy: 0.2224 - val_loss: 3.0850 - val_accuracy: 0.2280\n",
      "Epoch 9/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 3.0370 - accuracy: 0.2275 - val_loss: 3.0196 - val_accuracy: 0.2291\n",
      "Epoch 10/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.9718 - accuracy: 0.2360 - val_loss: 2.9624 - val_accuracy: 0.2337\n",
      "Epoch 11/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.9149 - accuracy: 0.2455 - val_loss: 2.9139 - val_accuracy: 0.2434\n",
      "Epoch 12/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.8637 - accuracy: 0.2568 - val_loss: 2.8721 - val_accuracy: 0.2514\n",
      "Epoch 13/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.8179 - accuracy: 0.2688 - val_loss: 2.8319 - val_accuracy: 0.2561\n",
      "Epoch 14/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.7757 - accuracy: 0.2768 - val_loss: 2.7977 - val_accuracy: 0.2657\n",
      "Epoch 15/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.7359 - accuracy: 0.2859 - val_loss: 2.7635 - val_accuracy: 0.2772\n",
      "Epoch 16/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.6986 - accuracy: 0.2953 - val_loss: 2.7333 - val_accuracy: 0.2796\n",
      "Epoch 17/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.6631 - accuracy: 0.3035 - val_loss: 2.7028 - val_accuracy: 0.2892\n",
      "Epoch 18/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.6288 - accuracy: 0.3112 - val_loss: 2.6719 - val_accuracy: 0.2988\n",
      "Epoch 19/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.5955 - accuracy: 0.3188 - val_loss: 2.6434 - val_accuracy: 0.3030\n",
      "Epoch 20/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.5623 - accuracy: 0.3252 - val_loss: 2.6154 - val_accuracy: 0.3073\n",
      "Epoch 21/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.5296 - accuracy: 0.3349 - val_loss: 2.5878 - val_accuracy: 0.3100\n",
      "Epoch 22/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.4971 - accuracy: 0.3425 - val_loss: 2.5605 - val_accuracy: 0.3169\n",
      "Epoch 23/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.4649 - accuracy: 0.3504 - val_loss: 2.5322 - val_accuracy: 0.3242\n",
      "Epoch 24/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.4325 - accuracy: 0.3568 - val_loss: 2.5046 - val_accuracy: 0.3338\n",
      "Epoch 25/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.4006 - accuracy: 0.3654 - val_loss: 2.4764 - val_accuracy: 0.3381\n",
      "Epoch 26/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.3687 - accuracy: 0.3731 - val_loss: 2.4502 - val_accuracy: 0.3427\n",
      "Epoch 27/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.3366 - accuracy: 0.3787 - val_loss: 2.4212 - val_accuracy: 0.3512\n",
      "Epoch 28/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.3051 - accuracy: 0.3863 - val_loss: 2.3942 - val_accuracy: 0.3573\n",
      "Epoch 29/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.2730 - accuracy: 0.3926 - val_loss: 2.3684 - val_accuracy: 0.3612\n",
      "Epoch 30/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.2410 - accuracy: 0.3978 - val_loss: 2.3408 - val_accuracy: 0.3658\n",
      "Epoch 31/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.2100 - accuracy: 0.4042 - val_loss: 2.3147 - val_accuracy: 0.3793\n",
      "Epoch 32/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.1796 - accuracy: 0.4148 - val_loss: 2.2889 - val_accuracy: 0.3793\n",
      "Epoch 33/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.1498 - accuracy: 0.4235 - val_loss: 2.2647 - val_accuracy: 0.3939\n",
      "Epoch 34/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.1205 - accuracy: 0.4366 - val_loss: 2.2386 - val_accuracy: 0.4024\n",
      "Epoch 35/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.0919 - accuracy: 0.4443 - val_loss: 2.2195 - val_accuracy: 0.4032\n",
      "Epoch 36/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.0643 - accuracy: 0.4511 - val_loss: 2.1940 - val_accuracy: 0.4136\n",
      "Epoch 37/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.0369 - accuracy: 0.4620 - val_loss: 2.1719 - val_accuracy: 0.4224\n",
      "Epoch 38/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 2.0103 - accuracy: 0.4657 - val_loss: 2.1527 - val_accuracy: 0.4209\n",
      "Epoch 39/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.9847 - accuracy: 0.4745 - val_loss: 2.1297 - val_accuracy: 0.4263\n",
      "Epoch 40/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.9591 - accuracy: 0.4777 - val_loss: 2.1108 - val_accuracy: 0.4328\n",
      "Epoch 41/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.9350 - accuracy: 0.4828 - val_loss: 2.0907 - val_accuracy: 0.4370\n",
      "Epoch 42/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.9110 - accuracy: 0.4868 - val_loss: 2.0753 - val_accuracy: 0.4382\n",
      "Epoch 43/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.8873 - accuracy: 0.4913 - val_loss: 2.0544 - val_accuracy: 0.4440\n",
      "Epoch 44/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.8642 - accuracy: 0.4961 - val_loss: 2.0378 - val_accuracy: 0.4471\n",
      "Epoch 45/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.8426 - accuracy: 0.5018 - val_loss: 2.0238 - val_accuracy: 0.4467\n",
      "Epoch 46/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.8211 - accuracy: 0.5088 - val_loss: 2.0047 - val_accuracy: 0.4513\n",
      "Epoch 47/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.8006 - accuracy: 0.5105 - val_loss: 1.9896 - val_accuracy: 0.4551\n",
      "Epoch 48/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.7801 - accuracy: 0.5181 - val_loss: 1.9743 - val_accuracy: 0.4586\n",
      "Epoch 49/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.7606 - accuracy: 0.5211 - val_loss: 1.9620 - val_accuracy: 0.4628\n",
      "Epoch 50/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.7415 - accuracy: 0.5255 - val_loss: 1.9472 - val_accuracy: 0.4582\n",
      "Epoch 51/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.7229 - accuracy: 0.5313 - val_loss: 1.9338 - val_accuracy: 0.4667\n",
      "Epoch 52/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.7055 - accuracy: 0.5338 - val_loss: 1.9217 - val_accuracy: 0.4705\n",
      "Epoch 53/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.6876 - accuracy: 0.5366 - val_loss: 1.9106 - val_accuracy: 0.4725\n",
      "Epoch 54/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.6709 - accuracy: 0.5423 - val_loss: 1.8981 - val_accuracy: 0.4771\n",
      "Epoch 55/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.6545 - accuracy: 0.5455 - val_loss: 1.8879 - val_accuracy: 0.4809\n",
      "Epoch 56/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.6385 - accuracy: 0.5496 - val_loss: 1.8792 - val_accuracy: 0.4809\n",
      "Epoch 57/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.6221 - accuracy: 0.5542 - val_loss: 1.8687 - val_accuracy: 0.4817\n",
      "Epoch 58/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.6072 - accuracy: 0.5571 - val_loss: 1.8572 - val_accuracy: 0.4809\n",
      "Epoch 59/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.5925 - accuracy: 0.5593 - val_loss: 1.8477 - val_accuracy: 0.4852\n",
      "Epoch 60/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.5774 - accuracy: 0.5653 - val_loss: 1.8380 - val_accuracy: 0.4871\n",
      "Epoch 61/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.5637 - accuracy: 0.5668 - val_loss: 1.8327 - val_accuracy: 0.4902\n",
      "Epoch 62/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.5500 - accuracy: 0.5715 - val_loss: 1.8242 - val_accuracy: 0.4906\n",
      "Epoch 63/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.5363 - accuracy: 0.5767 - val_loss: 1.8130 - val_accuracy: 0.4917\n",
      "Epoch 64/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.5233 - accuracy: 0.5786 - val_loss: 1.8072 - val_accuracy: 0.4929\n",
      "Epoch 65/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.5099 - accuracy: 0.5824 - val_loss: 1.8003 - val_accuracy: 0.4952\n",
      "Epoch 66/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.4973 - accuracy: 0.5846 - val_loss: 1.7932 - val_accuracy: 0.4990\n",
      "Epoch 67/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.4856 - accuracy: 0.5872 - val_loss: 1.7874 - val_accuracy: 0.5002\n",
      "Epoch 68/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.4733 - accuracy: 0.5899 - val_loss: 1.7792 - val_accuracy: 0.5040\n",
      "Epoch 69/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.4612 - accuracy: 0.5928 - val_loss: 1.7714 - val_accuracy: 0.5021\n",
      "Epoch 70/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.4496 - accuracy: 0.5951 - val_loss: 1.7672 - val_accuracy: 0.5075\n",
      "Epoch 71/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.4380 - accuracy: 0.5986 - val_loss: 1.7595 - val_accuracy: 0.5071\n",
      "Epoch 72/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.4272 - accuracy: 0.6013 - val_loss: 1.7550 - val_accuracy: 0.5106\n",
      "Epoch 73/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.4163 - accuracy: 0.6036 - val_loss: 1.7493 - val_accuracy: 0.5106\n",
      "Epoch 74/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.4056 - accuracy: 0.6047 - val_loss: 1.7433 - val_accuracy: 0.5114\n",
      "Epoch 75/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.3945 - accuracy: 0.6093 - val_loss: 1.7404 - val_accuracy: 0.5121\n",
      "Epoch 76/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.3844 - accuracy: 0.6122 - val_loss: 1.7334 - val_accuracy: 0.5133\n",
      "Epoch 77/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.3742 - accuracy: 0.6134 - val_loss: 1.7279 - val_accuracy: 0.5187\n",
      "Epoch 78/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.3644 - accuracy: 0.6153 - val_loss: 1.7257 - val_accuracy: 0.5152\n",
      "Epoch 79/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.3547 - accuracy: 0.6173 - val_loss: 1.7209 - val_accuracy: 0.5194\n",
      "Epoch 80/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.3447 - accuracy: 0.6204 - val_loss: 1.7188 - val_accuracy: 0.5183\n",
      "Epoch 81/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.3359 - accuracy: 0.6228 - val_loss: 1.7134 - val_accuracy: 0.5206\n",
      "Epoch 82/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.3263 - accuracy: 0.6242 - val_loss: 1.7104 - val_accuracy: 0.5206\n",
      "Epoch 83/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.3178 - accuracy: 0.6260 - val_loss: 1.7076 - val_accuracy: 0.5191\n",
      "Epoch 84/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.3092 - accuracy: 0.6290 - val_loss: 1.7031 - val_accuracy: 0.5202\n",
      "Epoch 85/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.3003 - accuracy: 0.6320 - val_loss: 1.6992 - val_accuracy: 0.5198\n",
      "Epoch 86/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.2913 - accuracy: 0.6333 - val_loss: 1.6976 - val_accuracy: 0.5171\n",
      "Epoch 87/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.2830 - accuracy: 0.6360 - val_loss: 1.6927 - val_accuracy: 0.5241\n",
      "Epoch 88/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.2746 - accuracy: 0.6394 - val_loss: 1.6908 - val_accuracy: 0.5248\n",
      "Epoch 89/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.2663 - accuracy: 0.6401 - val_loss: 1.6879 - val_accuracy: 0.5241\n",
      "Epoch 90/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.2590 - accuracy: 0.6419 - val_loss: 1.6841 - val_accuracy: 0.5264\n",
      "Epoch 91/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.2506 - accuracy: 0.6442 - val_loss: 1.6841 - val_accuracy: 0.5248\n",
      "Epoch 92/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.2431 - accuracy: 0.6461 - val_loss: 1.6816 - val_accuracy: 0.5225\n",
      "Epoch 93/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.2350 - accuracy: 0.6474 - val_loss: 1.6767 - val_accuracy: 0.5291\n",
      "Epoch 94/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.2275 - accuracy: 0.6478 - val_loss: 1.6794 - val_accuracy: 0.5314\n",
      "Epoch 95/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.2201 - accuracy: 0.6529 - val_loss: 1.6784 - val_accuracy: 0.5275\n",
      "Epoch 96/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.2133 - accuracy: 0.6525 - val_loss: 1.6765 - val_accuracy: 0.5260\n",
      "Epoch 97/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.2060 - accuracy: 0.6563 - val_loss: 1.6727 - val_accuracy: 0.5310\n",
      "Epoch 98/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.1986 - accuracy: 0.6579 - val_loss: 1.6727 - val_accuracy: 0.5345\n",
      "Epoch 99/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.1919 - accuracy: 0.6580 - val_loss: 1.6715 - val_accuracy: 0.5298\n",
      "Epoch 100/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.1854 - accuracy: 0.6593 - val_loss: 1.6719 - val_accuracy: 0.5318\n",
      "Epoch 101/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.1782 - accuracy: 0.6633 - val_loss: 1.6678 - val_accuracy: 0.5333\n",
      "Epoch 102/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.1713 - accuracy: 0.6645 - val_loss: 1.6652 - val_accuracy: 0.5348\n",
      "Epoch 103/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.1653 - accuracy: 0.6652 - val_loss: 1.6633 - val_accuracy: 0.5356\n",
      "Epoch 104/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.1580 - accuracy: 0.6679 - val_loss: 1.6649 - val_accuracy: 0.5352\n",
      "Epoch 105/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.1520 - accuracy: 0.6688 - val_loss: 1.6657 - val_accuracy: 0.5325\n",
      "Epoch 106/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.1457 - accuracy: 0.6691 - val_loss: 1.6657 - val_accuracy: 0.5364\n",
      "Epoch 107/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.1395 - accuracy: 0.6728 - val_loss: 1.6622 - val_accuracy: 0.5352\n",
      "Epoch 108/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.1336 - accuracy: 0.6748 - val_loss: 1.6608 - val_accuracy: 0.5379\n",
      "Epoch 109/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.1269 - accuracy: 0.6760 - val_loss: 1.6612 - val_accuracy: 0.5379\n",
      "Epoch 110/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.1213 - accuracy: 0.6760 - val_loss: 1.6607 - val_accuracy: 0.5352\n",
      "Epoch 111/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.1153 - accuracy: 0.6792 - val_loss: 1.6605 - val_accuracy: 0.5410\n",
      "Epoch 112/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.1093 - accuracy: 0.6802 - val_loss: 1.6623 - val_accuracy: 0.5379\n",
      "Epoch 113/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.1039 - accuracy: 0.6828 - val_loss: 1.6597 - val_accuracy: 0.5391\n",
      "Epoch 114/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0979 - accuracy: 0.6856 - val_loss: 1.6608 - val_accuracy: 0.5387\n",
      "Epoch 115/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0925 - accuracy: 0.6863 - val_loss: 1.6572 - val_accuracy: 0.5437\n",
      "Epoch 116/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0868 - accuracy: 0.6858 - val_loss: 1.6610 - val_accuracy: 0.5383\n",
      "Epoch 117/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0815 - accuracy: 0.6888 - val_loss: 1.6603 - val_accuracy: 0.5449\n",
      "Epoch 118/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0758 - accuracy: 0.6893 - val_loss: 1.6644 - val_accuracy: 0.5452\n",
      "Epoch 119/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0708 - accuracy: 0.6916 - val_loss: 1.6647 - val_accuracy: 0.5441\n",
      "Epoch 120/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0651 - accuracy: 0.6946 - val_loss: 1.6627 - val_accuracy: 0.5414\n",
      "Epoch 121/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0599 - accuracy: 0.6942 - val_loss: 1.6631 - val_accuracy: 0.5456\n",
      "Epoch 122/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0552 - accuracy: 0.6934 - val_loss: 1.6635 - val_accuracy: 0.5441\n",
      "Epoch 123/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0495 - accuracy: 0.6973 - val_loss: 1.6647 - val_accuracy: 0.5445\n",
      "Epoch 124/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0446 - accuracy: 0.6989 - val_loss: 1.6634 - val_accuracy: 0.5479\n",
      "Epoch 125/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0395 - accuracy: 0.7002 - val_loss: 1.6632 - val_accuracy: 0.5479\n",
      "Epoch 126/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0346 - accuracy: 0.6992 - val_loss: 1.6675 - val_accuracy: 0.5437\n",
      "Epoch 127/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0298 - accuracy: 0.7004 - val_loss: 1.6665 - val_accuracy: 0.5495\n",
      "Epoch 128/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0245 - accuracy: 0.7028 - val_loss: 1.6718 - val_accuracy: 0.5464\n",
      "Epoch 129/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0203 - accuracy: 0.7047 - val_loss: 1.6674 - val_accuracy: 0.5456\n",
      "Epoch 130/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0155 - accuracy: 0.7062 - val_loss: 1.6694 - val_accuracy: 0.5518\n",
      "Epoch 131/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0112 - accuracy: 0.7066 - val_loss: 1.6712 - val_accuracy: 0.5499\n",
      "Epoch 132/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0064 - accuracy: 0.7090 - val_loss: 1.6737 - val_accuracy: 0.5479\n",
      "Epoch 133/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 1.0015 - accuracy: 0.7094 - val_loss: 1.6743 - val_accuracy: 0.5533\n",
      "Epoch 134/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9973 - accuracy: 0.7103 - val_loss: 1.6717 - val_accuracy: 0.5503\n",
      "Epoch 135/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9927 - accuracy: 0.7113 - val_loss: 1.6772 - val_accuracy: 0.5460\n",
      "Epoch 136/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9886 - accuracy: 0.7142 - val_loss: 1.6777 - val_accuracy: 0.5522\n",
      "Epoch 137/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9836 - accuracy: 0.7147 - val_loss: 1.6798 - val_accuracy: 0.5468\n",
      "Epoch 138/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9797 - accuracy: 0.7172 - val_loss: 1.6825 - val_accuracy: 0.5537\n",
      "Epoch 139/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9748 - accuracy: 0.7172 - val_loss: 1.6856 - val_accuracy: 0.5499\n",
      "Epoch 140/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9709 - accuracy: 0.7181 - val_loss: 1.6819 - val_accuracy: 0.5518\n",
      "Epoch 141/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9665 - accuracy: 0.7195 - val_loss: 1.6871 - val_accuracy: 0.5479\n",
      "Epoch 142/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9625 - accuracy: 0.7192 - val_loss: 1.6901 - val_accuracy: 0.5522\n",
      "Epoch 143/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9587 - accuracy: 0.7210 - val_loss: 1.6931 - val_accuracy: 0.5503\n",
      "Epoch 144/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9541 - accuracy: 0.7242 - val_loss: 1.6941 - val_accuracy: 0.5529\n",
      "Epoch 145/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9499 - accuracy: 0.7248 - val_loss: 1.6997 - val_accuracy: 0.5522\n",
      "Epoch 146/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9464 - accuracy: 0.7274 - val_loss: 1.7011 - val_accuracy: 0.5491\n",
      "Epoch 147/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9421 - accuracy: 0.7261 - val_loss: 1.7024 - val_accuracy: 0.5510\n",
      "Epoch 148/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9383 - accuracy: 0.7288 - val_loss: 1.7025 - val_accuracy: 0.5529\n",
      "Epoch 149/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9344 - accuracy: 0.7268 - val_loss: 1.7050 - val_accuracy: 0.5487\n",
      "Epoch 150/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9303 - accuracy: 0.7306 - val_loss: 1.7112 - val_accuracy: 0.5495\n",
      "Epoch 151/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9264 - accuracy: 0.7297 - val_loss: 1.7077 - val_accuracy: 0.5483\n",
      "Epoch 152/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9227 - accuracy: 0.7319 - val_loss: 1.7118 - val_accuracy: 0.5483\n",
      "Epoch 153/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9190 - accuracy: 0.7354 - val_loss: 1.7131 - val_accuracy: 0.5491\n",
      "Epoch 154/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9150 - accuracy: 0.7343 - val_loss: 1.7172 - val_accuracy: 0.5456\n",
      "Epoch 155/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9116 - accuracy: 0.7362 - val_loss: 1.7214 - val_accuracy: 0.5472\n",
      "Epoch 156/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9082 - accuracy: 0.7368 - val_loss: 1.7208 - val_accuracy: 0.5472\n",
      "Epoch 157/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.9038 - accuracy: 0.7361 - val_loss: 1.7253 - val_accuracy: 0.5445\n",
      "Epoch 158/300\n",
      "379/379 [==============================] - 1s 4ms/step - loss: 0.9007 - accuracy: 0.7403 - val_loss: 1.7248 - val_accuracy: 0.5464\n",
      "Epoch 159/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8969 - accuracy: 0.7393 - val_loss: 1.7264 - val_accuracy: 0.5456\n",
      "Epoch 160/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8935 - accuracy: 0.7424 - val_loss: 1.7354 - val_accuracy: 0.5418\n",
      "Epoch 161/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8894 - accuracy: 0.7424 - val_loss: 1.7328 - val_accuracy: 0.5479\n",
      "Epoch 162/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8865 - accuracy: 0.7439 - val_loss: 1.7351 - val_accuracy: 0.5464\n",
      "Epoch 163/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8827 - accuracy: 0.7441 - val_loss: 1.7410 - val_accuracy: 0.5483\n",
      "Epoch 164/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8795 - accuracy: 0.7442 - val_loss: 1.7430 - val_accuracy: 0.5483\n",
      "Epoch 165/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8760 - accuracy: 0.7481 - val_loss: 1.7500 - val_accuracy: 0.5495\n",
      "Epoch 166/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8727 - accuracy: 0.7478 - val_loss: 1.7515 - val_accuracy: 0.5487\n",
      "Epoch 167/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8693 - accuracy: 0.7480 - val_loss: 1.7510 - val_accuracy: 0.5499\n",
      "Epoch 168/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8655 - accuracy: 0.7501 - val_loss: 1.7526 - val_accuracy: 0.5499\n",
      "Epoch 169/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8629 - accuracy: 0.7508 - val_loss: 1.7617 - val_accuracy: 0.5503\n",
      "Epoch 170/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8588 - accuracy: 0.7498 - val_loss: 1.7633 - val_accuracy: 0.5476\n",
      "Epoch 171/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8557 - accuracy: 0.7531 - val_loss: 1.7639 - val_accuracy: 0.5476\n",
      "Epoch 172/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8526 - accuracy: 0.7536 - val_loss: 1.7665 - val_accuracy: 0.5491\n",
      "Epoch 173/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8495 - accuracy: 0.7560 - val_loss: 1.7748 - val_accuracy: 0.5433\n",
      "Epoch 174/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8457 - accuracy: 0.7546 - val_loss: 1.7757 - val_accuracy: 0.5452\n",
      "Epoch 175/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8427 - accuracy: 0.7576 - val_loss: 1.7822 - val_accuracy: 0.5437\n",
      "Epoch 176/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8395 - accuracy: 0.7557 - val_loss: 1.7861 - val_accuracy: 0.5464\n",
      "Epoch 177/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8365 - accuracy: 0.7581 - val_loss: 1.7846 - val_accuracy: 0.5487\n",
      "Epoch 178/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8333 - accuracy: 0.7600 - val_loss: 1.7855 - val_accuracy: 0.5476\n",
      "Epoch 179/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8308 - accuracy: 0.7595 - val_loss: 1.7923 - val_accuracy: 0.5460\n",
      "Epoch 180/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8278 - accuracy: 0.7620 - val_loss: 1.7911 - val_accuracy: 0.5468\n",
      "Epoch 181/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8242 - accuracy: 0.7618 - val_loss: 1.7989 - val_accuracy: 0.5445\n",
      "Epoch 182/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8215 - accuracy: 0.7623 - val_loss: 1.8052 - val_accuracy: 0.5472\n",
      "Epoch 183/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8177 - accuracy: 0.7629 - val_loss: 1.8021 - val_accuracy: 0.5460\n",
      "Epoch 184/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8154 - accuracy: 0.7631 - val_loss: 1.8089 - val_accuracy: 0.5441\n",
      "Epoch 185/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8118 - accuracy: 0.7660 - val_loss: 1.8162 - val_accuracy: 0.5460\n",
      "Epoch 186/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8087 - accuracy: 0.7667 - val_loss: 1.8199 - val_accuracy: 0.5491\n",
      "Epoch 187/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8060 - accuracy: 0.7683 - val_loss: 1.8198 - val_accuracy: 0.5483\n",
      "Epoch 188/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8035 - accuracy: 0.7675 - val_loss: 1.8243 - val_accuracy: 0.5456\n",
      "Epoch 189/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8003 - accuracy: 0.7684 - val_loss: 1.8287 - val_accuracy: 0.5445\n",
      "Epoch 190/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7976 - accuracy: 0.7689 - val_loss: 1.8302 - val_accuracy: 0.5464\n",
      "Epoch 191/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7948 - accuracy: 0.7700 - val_loss: 1.8362 - val_accuracy: 0.5495\n",
      "Epoch 192/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7920 - accuracy: 0.7700 - val_loss: 1.8404 - val_accuracy: 0.5518\n",
      "Epoch 193/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7887 - accuracy: 0.7722 - val_loss: 1.8474 - val_accuracy: 0.5479\n",
      "Epoch 194/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7861 - accuracy: 0.7710 - val_loss: 1.8451 - val_accuracy: 0.5452\n",
      "Epoch 195/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7838 - accuracy: 0.7742 - val_loss: 1.8505 - val_accuracy: 0.5479\n",
      "Epoch 196/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7800 - accuracy: 0.7743 - val_loss: 1.8573 - val_accuracy: 0.5464\n",
      "Epoch 197/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7769 - accuracy: 0.7735 - val_loss: 1.8626 - val_accuracy: 0.5456\n",
      "Epoch 198/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7746 - accuracy: 0.7755 - val_loss: 1.8653 - val_accuracy: 0.5433\n",
      "Epoch 199/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7718 - accuracy: 0.7757 - val_loss: 1.8670 - val_accuracy: 0.5429\n",
      "Epoch 200/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7694 - accuracy: 0.7773 - val_loss: 1.8694 - val_accuracy: 0.5503\n",
      "Epoch 201/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7668 - accuracy: 0.7774 - val_loss: 1.8772 - val_accuracy: 0.5464\n",
      "Epoch 202/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7629 - accuracy: 0.7782 - val_loss: 1.8806 - val_accuracy: 0.5445\n",
      "Epoch 203/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7610 - accuracy: 0.7795 - val_loss: 1.8865 - val_accuracy: 0.5452\n",
      "Epoch 204/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7582 - accuracy: 0.7798 - val_loss: 1.8936 - val_accuracy: 0.5476\n",
      "Epoch 205/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7561 - accuracy: 0.7801 - val_loss: 1.8947 - val_accuracy: 0.5449\n",
      "Epoch 206/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7535 - accuracy: 0.7825 - val_loss: 1.8965 - val_accuracy: 0.5460\n",
      "Epoch 207/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7504 - accuracy: 0.7818 - val_loss: 1.9083 - val_accuracy: 0.5479\n",
      "Epoch 208/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7474 - accuracy: 0.7824 - val_loss: 1.9095 - val_accuracy: 0.5429\n",
      "Epoch 209/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7455 - accuracy: 0.7846 - val_loss: 1.9176 - val_accuracy: 0.5456\n",
      "Epoch 210/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7426 - accuracy: 0.7855 - val_loss: 1.9158 - val_accuracy: 0.5429\n",
      "Epoch 211/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7404 - accuracy: 0.7856 - val_loss: 1.9190 - val_accuracy: 0.5468\n",
      "Epoch 212/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7373 - accuracy: 0.7868 - val_loss: 1.9261 - val_accuracy: 0.5441\n",
      "Epoch 213/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7349 - accuracy: 0.7865 - val_loss: 1.9372 - val_accuracy: 0.5487\n",
      "Epoch 214/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7323 - accuracy: 0.7890 - val_loss: 1.9403 - val_accuracy: 0.5414\n",
      "Epoch 215/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7298 - accuracy: 0.7887 - val_loss: 1.9381 - val_accuracy: 0.5449\n",
      "Epoch 216/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7284 - accuracy: 0.7886 - val_loss: 1.9438 - val_accuracy: 0.5468\n",
      "Epoch 217/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7252 - accuracy: 0.7900 - val_loss: 1.9523 - val_accuracy: 0.5479\n",
      "Epoch 218/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7224 - accuracy: 0.7908 - val_loss: 1.9588 - val_accuracy: 0.5441\n",
      "Epoch 219/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7204 - accuracy: 0.7901 - val_loss: 1.9593 - val_accuracy: 0.5452\n",
      "Epoch 220/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7176 - accuracy: 0.7917 - val_loss: 1.9589 - val_accuracy: 0.5533\n",
      "Epoch 221/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7156 - accuracy: 0.7926 - val_loss: 1.9651 - val_accuracy: 0.5468\n",
      "Epoch 222/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7132 - accuracy: 0.7949 - val_loss: 1.9713 - val_accuracy: 0.5510\n",
      "Epoch 223/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7106 - accuracy: 0.7931 - val_loss: 1.9768 - val_accuracy: 0.5445\n",
      "Epoch 224/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7081 - accuracy: 0.7960 - val_loss: 1.9817 - val_accuracy: 0.5468\n",
      "Epoch 225/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7062 - accuracy: 0.7972 - val_loss: 1.9882 - val_accuracy: 0.5476\n",
      "Epoch 226/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7038 - accuracy: 0.7958 - val_loss: 1.9945 - val_accuracy: 0.5495\n",
      "Epoch 227/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.7006 - accuracy: 0.7971 - val_loss: 1.9965 - val_accuracy: 0.5452\n",
      "Epoch 228/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6989 - accuracy: 0.7985 - val_loss: 1.9998 - val_accuracy: 0.5483\n",
      "Epoch 229/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6963 - accuracy: 0.8001 - val_loss: 2.0107 - val_accuracy: 0.5503\n",
      "Epoch 230/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6941 - accuracy: 0.7995 - val_loss: 2.0130 - val_accuracy: 0.5506\n",
      "Epoch 231/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6914 - accuracy: 0.8001 - val_loss: 2.0146 - val_accuracy: 0.5460\n",
      "Epoch 232/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6896 - accuracy: 0.8029 - val_loss: 2.0259 - val_accuracy: 0.5452\n",
      "Epoch 233/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6874 - accuracy: 0.8001 - val_loss: 2.0259 - val_accuracy: 0.5456\n",
      "Epoch 234/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6847 - accuracy: 0.8014 - val_loss: 2.0310 - val_accuracy: 0.5468\n",
      "Epoch 235/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6827 - accuracy: 0.8032 - val_loss: 2.0379 - val_accuracy: 0.5483\n",
      "Epoch 236/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6814 - accuracy: 0.8021 - val_loss: 2.0433 - val_accuracy: 0.5479\n",
      "Epoch 237/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6779 - accuracy: 0.8039 - val_loss: 2.0493 - val_accuracy: 0.5449\n",
      "Epoch 238/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6765 - accuracy: 0.8060 - val_loss: 2.0584 - val_accuracy: 0.5487\n",
      "Epoch 239/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6736 - accuracy: 0.8062 - val_loss: 2.0564 - val_accuracy: 0.5449\n",
      "Epoch 240/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6715 - accuracy: 0.8054 - val_loss: 2.0607 - val_accuracy: 0.5487\n",
      "Epoch 241/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6693 - accuracy: 0.8063 - val_loss: 2.0667 - val_accuracy: 0.5518\n",
      "Epoch 242/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6675 - accuracy: 0.8071 - val_loss: 2.0744 - val_accuracy: 0.5456\n",
      "Epoch 243/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6652 - accuracy: 0.8082 - val_loss: 2.0782 - val_accuracy: 0.5472\n",
      "Epoch 244/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6629 - accuracy: 0.8091 - val_loss: 2.0816 - val_accuracy: 0.5491\n",
      "Epoch 245/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6610 - accuracy: 0.8095 - val_loss: 2.0916 - val_accuracy: 0.5476\n",
      "Epoch 246/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6590 - accuracy: 0.8110 - val_loss: 2.0926 - val_accuracy: 0.5506\n",
      "Epoch 247/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6565 - accuracy: 0.8101 - val_loss: 2.1038 - val_accuracy: 0.5487\n",
      "Epoch 248/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6546 - accuracy: 0.8115 - val_loss: 2.1141 - val_accuracy: 0.5437\n",
      "Epoch 249/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6524 - accuracy: 0.8119 - val_loss: 2.1078 - val_accuracy: 0.5518\n",
      "Epoch 250/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6506 - accuracy: 0.8142 - val_loss: 2.1141 - val_accuracy: 0.5445\n",
      "Epoch 251/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6481 - accuracy: 0.8131 - val_loss: 2.1227 - val_accuracy: 0.5495\n",
      "Epoch 252/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6459 - accuracy: 0.8154 - val_loss: 2.1258 - val_accuracy: 0.5433\n",
      "Epoch 253/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6436 - accuracy: 0.8156 - val_loss: 2.1340 - val_accuracy: 0.5441\n",
      "Epoch 254/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6419 - accuracy: 0.8175 - val_loss: 2.1360 - val_accuracy: 0.5479\n",
      "Epoch 255/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6404 - accuracy: 0.8172 - val_loss: 2.1456 - val_accuracy: 0.5449\n",
      "Epoch 256/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6372 - accuracy: 0.8180 - val_loss: 2.1565 - val_accuracy: 0.5441\n",
      "Epoch 257/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6356 - accuracy: 0.8200 - val_loss: 2.1611 - val_accuracy: 0.5445\n",
      "Epoch 258/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6334 - accuracy: 0.8196 - val_loss: 2.1630 - val_accuracy: 0.5441\n",
      "Epoch 259/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6315 - accuracy: 0.8193 - val_loss: 2.1663 - val_accuracy: 0.5479\n",
      "Epoch 260/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6297 - accuracy: 0.8196 - val_loss: 2.1708 - val_accuracy: 0.5441\n",
      "Epoch 261/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6280 - accuracy: 0.8200 - val_loss: 2.1764 - val_accuracy: 0.5422\n",
      "Epoch 262/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6262 - accuracy: 0.8190 - val_loss: 2.1843 - val_accuracy: 0.5452\n",
      "Epoch 263/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6236 - accuracy: 0.8219 - val_loss: 2.1895 - val_accuracy: 0.5479\n",
      "Epoch 264/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6219 - accuracy: 0.8235 - val_loss: 2.1908 - val_accuracy: 0.5414\n",
      "Epoch 265/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6192 - accuracy: 0.8227 - val_loss: 2.2018 - val_accuracy: 0.5449\n",
      "Epoch 266/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6166 - accuracy: 0.8246 - val_loss: 2.2076 - val_accuracy: 0.5391\n",
      "Epoch 267/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6150 - accuracy: 0.8243 - val_loss: 2.2159 - val_accuracy: 0.5433\n",
      "Epoch 268/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6137 - accuracy: 0.8257 - val_loss: 2.2174 - val_accuracy: 0.5441\n",
      "Epoch 269/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6113 - accuracy: 0.8257 - val_loss: 2.2258 - val_accuracy: 0.5472\n",
      "Epoch 270/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6101 - accuracy: 0.8251 - val_loss: 2.2285 - val_accuracy: 0.5387\n",
      "Epoch 271/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6079 - accuracy: 0.8258 - val_loss: 2.2413 - val_accuracy: 0.5460\n",
      "Epoch 272/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6052 - accuracy: 0.8289 - val_loss: 2.2464 - val_accuracy: 0.5387\n",
      "Epoch 273/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6045 - accuracy: 0.8308 - val_loss: 2.2566 - val_accuracy: 0.5456\n",
      "Epoch 274/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6023 - accuracy: 0.8300 - val_loss: 2.2585 - val_accuracy: 0.5445\n",
      "Epoch 275/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.6011 - accuracy: 0.8292 - val_loss: 2.2640 - val_accuracy: 0.5437\n",
      "Epoch 276/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5990 - accuracy: 0.8314 - val_loss: 2.2693 - val_accuracy: 0.5433\n",
      "Epoch 277/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5970 - accuracy: 0.8313 - val_loss: 2.2734 - val_accuracy: 0.5422\n",
      "Epoch 278/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5954 - accuracy: 0.8308 - val_loss: 2.2813 - val_accuracy: 0.5487\n",
      "Epoch 279/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5933 - accuracy: 0.8336 - val_loss: 2.2886 - val_accuracy: 0.5449\n",
      "Epoch 280/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5918 - accuracy: 0.8334 - val_loss: 2.2947 - val_accuracy: 0.5460\n",
      "Epoch 281/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5904 - accuracy: 0.8307 - val_loss: 2.3007 - val_accuracy: 0.5460\n",
      "Epoch 282/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5879 - accuracy: 0.8345 - val_loss: 2.2993 - val_accuracy: 0.5464\n",
      "Epoch 283/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5864 - accuracy: 0.8341 - val_loss: 2.3159 - val_accuracy: 0.5437\n",
      "Epoch 284/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5851 - accuracy: 0.8351 - val_loss: 2.3174 - val_accuracy: 0.5456\n",
      "Epoch 285/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5831 - accuracy: 0.8342 - val_loss: 2.3239 - val_accuracy: 0.5464\n",
      "Epoch 286/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5815 - accuracy: 0.8342 - val_loss: 2.3305 - val_accuracy: 0.5425\n",
      "Epoch 287/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5799 - accuracy: 0.8352 - val_loss: 2.3405 - val_accuracy: 0.5472\n",
      "Epoch 288/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5778 - accuracy: 0.8373 - val_loss: 2.3425 - val_accuracy: 0.5429\n",
      "Epoch 289/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5764 - accuracy: 0.8367 - val_loss: 2.3537 - val_accuracy: 0.5449\n",
      "Epoch 290/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5749 - accuracy: 0.8364 - val_loss: 2.3556 - val_accuracy: 0.5464\n",
      "Epoch 291/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5726 - accuracy: 0.8397 - val_loss: 2.3650 - val_accuracy: 0.5387\n",
      "Epoch 292/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5712 - accuracy: 0.8390 - val_loss: 2.3692 - val_accuracy: 0.5464\n",
      "Epoch 293/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5699 - accuracy: 0.8413 - val_loss: 2.3837 - val_accuracy: 0.5487\n",
      "Epoch 294/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5682 - accuracy: 0.8372 - val_loss: 2.3874 - val_accuracy: 0.5456\n",
      "Epoch 295/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5658 - accuracy: 0.8414 - val_loss: 2.3900 - val_accuracy: 0.5449\n",
      "Epoch 296/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5645 - accuracy: 0.8411 - val_loss: 2.3909 - val_accuracy: 0.5387\n",
      "Epoch 297/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5628 - accuracy: 0.8421 - val_loss: 2.4017 - val_accuracy: 0.5479\n",
      "Epoch 298/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5616 - accuracy: 0.8413 - val_loss: 2.4083 - val_accuracy: 0.5476\n",
      "Epoch 299/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5597 - accuracy: 0.8430 - val_loss: 2.4143 - val_accuracy: 0.5425\n",
      "Epoch 300/300\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.5577 - accuracy: 0.8445 - val_loss: 2.4241 - val_accuracy: 0.5441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb1a0732750>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# late fusion model training\n",
    "periphery_model.fit(x=periphery_train, y=labels_train, epochs=300, validation_data=(periphery_val, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fbfe609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2852633b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 23:20:51.738906: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1824098304 exceeds 10% of free system memory.\n",
      "2021-12-05 23:20:52.741816: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1824098304 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 23:20:54.516042: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 32s 58ms/step - loss: 8.0575 - accuracy: 0.0897 - val_loss: 4.3529 - val_accuracy: 0.0874\n",
      "Epoch 2/10\n",
      "379/379 [==============================] - 21s 56ms/step - loss: 4.3384 - accuracy: 0.0923 - val_loss: 4.3237 - val_accuracy: 0.1174\n",
      "Epoch 3/10\n",
      "379/379 [==============================] - 21s 56ms/step - loss: 4.3096 - accuracy: 0.1180 - val_loss: 4.2951 - val_accuracy: 0.1174\n",
      "Epoch 4/10\n",
      "379/379 [==============================] - 21s 56ms/step - loss: 4.2814 - accuracy: 0.1180 - val_loss: 4.2672 - val_accuracy: 0.1174\n",
      "Epoch 5/10\n",
      "379/379 [==============================] - 21s 56ms/step - loss: 4.2539 - accuracy: 0.1180 - val_loss: 4.2400 - val_accuracy: 0.1174\n",
      "Epoch 6/10\n",
      "379/379 [==============================] - 21s 56ms/step - loss: 4.2270 - accuracy: 0.1180 - val_loss: 4.2133 - val_accuracy: 0.1174\n",
      "Epoch 7/10\n",
      "379/379 [==============================] - 21s 56ms/step - loss: 4.2008 - accuracy: 0.1180 - val_loss: 4.1874 - val_accuracy: 0.1174\n",
      "Epoch 8/10\n",
      "379/379 [==============================] - 21s 56ms/step - loss: 4.1753 - accuracy: 0.1180 - val_loss: 4.1622 - val_accuracy: 0.1174\n",
      "Epoch 9/10\n",
      "379/379 [==============================] - 21s 56ms/step - loss: 4.1504 - accuracy: 0.1180 - val_loss: 4.1377 - val_accuracy: 0.1174\n",
      "Epoch 10/10\n",
      "379/379 [==============================] - 21s 56ms/step - loss: 4.1262 - accuracy: 0.1180 - val_loss: 4.1137 - val_accuracy: 0.1174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb1bcd7a790>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# late fusion model training\n",
    "image_model.fit(x=image_train, y=labels_train, epochs=10, validation_data=(image_val, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c9fcebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation \n",
    "image_prediction = image_model.predict(image_test)\n",
    "periphery_prediction = periphery_model.predict(periphery_test)\n",
    "late_fusion_prediction = 0.999*periphery_prediction + 0.001*image_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "565c2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.argmax(late_fusion_prediction, axis=1)\n",
    "y_test=np.argmax(labels_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6b9ec1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1854: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22458205467128478"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bb273945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.536003080477474"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
